{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "56bc6014-d3a1-496d-b0fa-5c90e5bdc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import pickle \n",
    "import json\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from lshiftml.feature_utils.parallel import get_features_in_parallel\n",
    "from rascal.representations import SphericalInvariants as SOAP\n",
    "from rascal.neighbourlist.structure_manager import mask_center_atoms_by_species\n",
    "from skcosmo.preprocessing import StandardFlexibleScaler\n",
    "import numpy as np\n",
    "import ase\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dd457b3d-62c2-4358-a849-fd5f7e5f8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c97600a3-02a4-441c-8430-312c0717072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,n_hidden,activation,num_input):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        #This is the pretrained_RELU stack\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_input,n_hidden),\n",
    "            nn.LayerNorm(n_hidden),\n",
    "            activation(),\n",
    "            nn.Linear(n_hidden,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class NeuralNetwork_bak(nn.Module):\n",
    "    def __init__(self,l1):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #nn.Dropout(p=0.2),\n",
    "            nn.Linear(num_input, l1),\n",
    "            nn.LayerNorm(l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l1,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "def NN_factory(**kwargs):\n",
    "    #this is necessary because pytorch changes the layer state dict keys when using averaged models\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    model = NeuralNetwork(**kwargs)\n",
    "    return AveragedModel(model)\n",
    "    \n",
    "    \n",
    "\n",
    "class ShiftMLNN:\n",
    "    \n",
    "    DEFAULT_MODEL_PATH = {\"v1\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v1/large_model_{}_{}_float64_opt.pth\",\n",
    "                         \"v2\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v2/large_model_{}_{}_float64_opt.pth\"}\n",
    "    DEFAULT_FEATURE_SCALER_PATH = {\"v1\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v1/scaler_features_{}_model_no_{}_float64_opt.pkl\",\n",
    "                                  \"v2\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v2/scaler_features_{}_model_no_{}_float64_opt.pkl\"}\n",
    "    DEFAULT_LABEL_SCALER_PATH = {\"v1\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v1/scaler_labels_{}_model_no_{}_float64_opt.pkl\",\n",
    "                                  \"v2\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v2/scaler_labels_{}_model_no_{}_float64_opt.pkl\"\n",
    "                                }\n",
    "    DEFAULT_HYPERS_PATH = {\"v1\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v1/{}_hypers.json\",\"v2\":\"/ssd/scratch/kellner/ShiftML-Light/src/lshiftml/models/NN_model_data/NN_v2/{}_hypers.json\"}\n",
    "    \n",
    "    default_architecture_dict = {\"v2\":{1:{\"n_hidden\":512,\"activation\":nn.Softplus,\"num_input\":3780},\n",
    "                                 6:{\"n_hidden\":256, \"activation\":nn.Tanh,\"num_input\":3780},\n",
    "                                 7:{\"n_hidden\":16,\"activation\":nn.Softplus,\"num_input\":3780},\n",
    "                                 8:{\"n_hidden\":512,\"activation\":nn.Tanh,\"num_input\":3780}},\n",
    "                                 \"v1\":{1:{\"n_hidden\":256,\"activation\":nn.ReLU,\"num_input\":60},\n",
    "                                      6:{\"n_hidden\":512,\"activation\":nn.ReLU,\"num_input\":60},\n",
    "                                      7:{\"n_hidden\":1024,\"activation\":nn.ReLU,\"num_input\":60},\n",
    "                                      8:{\"n_hidden\":512,\"activation\":nn.ReLU,\"num_input\":60}\n",
    "                                }}\n",
    "    \n",
    "    def __init__(self,trained_for=[1,6,7,8],defined_for=[1,6,7,8,16],bodyorder=\"v1\",model_architecture=NN_factory,architecture_dict=None,n_models=16,MODEL_PATH=None \\\n",
    "                 ,FEATURE_SCALER_PATH=None, LABEL_SCALER_PATH=None,HYPERS_PATH=None):\n",
    "        \n",
    "        \"\"\"initializes model by loading state dicts,\n",
    "           initializing pytorch model objects \n",
    "           and loading skcosmo flexible scalers\n",
    "           \n",
    "           bodyorder hyperparameter is ignored when choosing own architecture\n",
    "        \"\"\"\n",
    "        \n",
    "        self.species = trained_for\n",
    "        self.defined = defined_for\n",
    "        self.label_scalers = {k:[] for k in trained_for}\n",
    "        self.feature_scalers = {k:[] for k in trained_for}\n",
    "        #self.feature_means\n",
    "        #self.feature_vars\n",
    "        self.models = {k:[] for k in trained_for}\n",
    "        self.hypers = {k:None for k in trained_for}\n",
    "        \n",
    "        self._MODEL_PATH = self.DEFAULT_MODEL_PATH[bodyorder] if MODEL_PATH is None else MODEL_PATH\n",
    "        self._FEATURE_SCALER_PATH = self.DEFAULT_FEATURE_SCALER_PATH[bodyorder] if FEATURE_SCALER_PATH is None else FEATURE_SCALER_PATH\n",
    "        self._LABEL_SCALER_PATH = self.DEFAULT_LABEL_SCALER_PATH[bodyorder] if LABEL_SCALER_PATH is None else LABEL_SCALER_PATH\n",
    "        self._HYPERS_PATH = self.DEFAULT_HYPERS_PATH[bodyorder] if HYPERS_PATH is None else HYPERS_PATH\n",
    "        \n",
    "        #this is incredibly stupid and I should have never done that\n",
    "        self._architecture_dict = self.default_architecture_dict[bodyorder] if architecture_dict is None else architecture_dict\n",
    "        \n",
    "        for specie in trained_for:\n",
    "            \n",
    "            with open(self._HYPERS_PATH.format(specie),\"r\") as fg:\n",
    "                hypers = json.load(fg)\n",
    "            \n",
    "            self.hypers[specie] = hypers\n",
    "            \n",
    "            for n in range(n_models):\n",
    "                \n",
    "                model = model_architecture(**self._architecture_dict[specie])\n",
    "                state_dict = torch.load(self._MODEL_PATH.format(specie,n),map_location ='cpu')\n",
    "                model.load_state_dict(state_dict)\n",
    "                self.models[specie].append(model)\n",
    "                \n",
    "                #this is crap. replace by json?\n",
    "                with open(self._FEATURE_SCALER_PATH.format(specie,n),\"rb\") as fg:\n",
    "                    feature_scaler = pickle.load(fg)\n",
    "                with open(self._LABEL_SCALER_PATH.format(specie,n),\"rb\") as fg:    \n",
    "                    label_scaler = pickle.load(fg)\n",
    "                    \n",
    "                self.feature_scalers[specie].append(feature_scaler)\n",
    "                self.label_scalers[specie].append(label_scaler)\n",
    "        \n",
    "    \n",
    "    def predict(self,frames,predict_for=None,output=\"average\"):\n",
    "        \n",
    "        #assuming wrapped frames\n",
    "        results = {}\n",
    "        atomic_numbers = []\n",
    "        \n",
    "        is_single_frame = isinstance(frames,ase.atoms.Atoms)\n",
    "        \n",
    "        if is_single_frame:\n",
    "            atomic_numbers = frames.numbers\n",
    "        else:\n",
    "            for frame in frames:\n",
    "                atomic_numbers.append(frame.numbers)\n",
    "            \n",
    "        \n",
    "        atomic_numbers = np.hstack(atomic_numbers)\n",
    "        atomic_species = np.unique(atomic_numbers)\n",
    "        \n",
    "        for specie in atomic_species:\n",
    "            if specie not in self.defined:\n",
    "                raise NotImplementedError(\"Model not defined for specie {}\".format(specie))            \n",
    "        \n",
    "        if predict_for is None:\n",
    "            predict_for = self.species\n",
    "            \n",
    "        for specie in predict_for:\n",
    "            if specie not in self.species:\n",
    "                raise NotImplementedError(\"Model not trained for specie {}\".format(specie))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #avoids completely masked frames for rascal\n",
    "\n",
    "            \n",
    "        predict_for = np.intersect1d(atomic_species,predict_for)\n",
    "        predict_for = [int(specie) for specie in predict_for]\n",
    "                    \n",
    "        for specie in predict_for:\n",
    "            if is_single_frame:\n",
    "                frames.arrays.pop(\"center_atoms_mask\",None)\n",
    "                mask_center_atoms_by_species(frames,species_select=[specie])\n",
    "            else:\n",
    "                for frame in frames: \n",
    "                    frame.arrays.pop(\"center_atoms_mask\",None)\n",
    "                    mask_center_atoms_by_species(frame,species_select=[specie])\n",
    "            \n",
    "\n",
    "            if is_single_frame: \n",
    "                soap = SOAP(**self.hypers[specie])\n",
    "                Xpredict = soap.transform(frames).get_features(soap)\n",
    "            else:\n",
    "                Xpredict = get_features_in_parallel(frames,SOAP,self.hypers[specie])\n",
    "            predictions = []\n",
    "            \n",
    "            for model,feature_scaler,label_scaler in \\\n",
    "                zip(self.models[specie],self.feature_scalers[specie],self.label_scalers[specie]):\n",
    "                \n",
    "                #TODO: does the scaler also work on tensors?\n",
    "\n",
    "                Xpredict_scaled = feature_scaler.transform(Xpredict)\n",
    "                \n",
    "                #costs O(N): https://stsievert.com/blog/2017/09/07/pytorch/\n",
    "                Xpredict_scaled = torch.from_numpy(Xpredict_scaled)\n",
    "\n",
    "                with torch.no_grad(): #13 sec\n",
    "                    Y_predict = model(Xpredict_scaled)\n",
    "\n",
    "                Y_predict_inverse_rescaled = label_scaler.inverse_transform(Y_predict.numpy().reshape(-1,1))\n",
    "\n",
    "                \n",
    "                predictions.append(Y_predict_inverse_rescaled)\n",
    "            \n",
    "            results[specie] = np.hstack(predictions)\n",
    "            \n",
    "            if output == \"average\":\n",
    "                average = np.mean(results[specie],axis=1)\n",
    "                variance = np.var(results[specie],axis=1)\n",
    "                results[specie] = np.vstack([average,variance]).T\n",
    "            elif output == \"raw\":\n",
    "                continue\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "            #quick test to check whether copying in scaler worked\n",
    "            #print(np.allclose(Xpredict,get_features_in_parallel(frames,SOAP,self.hypers[specie])))\n",
    "        \n",
    "        return results\n",
    "        #gen feat\n",
    "        \n",
    "        #scale feat\n",
    "        #if scaling is False: skip\n",
    "        #\n",
    "        #inverse_scale predictions\n",
    "        #if inverse_scale is false: skip\n",
    "        #\n",
    "        #check option, return full predictions or average and variance\n",
    "        #return framewise, or full ?\n",
    "        \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "4c62aa4b-f1b3-4839-af37-cb5fd1ed0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftMLRR:\n",
    "    \n",
    "    DEFAULT_MODEL_PATH = {\"v1\":\"/ssd/scratch/kellner/COSMO_project/uncertainty/multi_ridge_v1/specie_{}_model_no_{}_name_clf\",\n",
    "                         \"v2\":\"/ssd/scratch/kellner/COSMO_project/uncertainty/multi_ridge_v2/{}_{}_name_clf\"}\n",
    "    DEFAULT_HYPERS_PATH = {\"v1\":\"/ssd/scratch/kellner/COSMO_project/uncertainty/multi_ridge_v1/specie_{}_model_no_0_hypers.json\",\"v2\":\"/ssd/scratch/kellner/COSMO_project/uncertainty/multi_ridge_v2/{}_0_hypers.json\"}\n",
    "    \n",
    "    \n",
    "    def __init__(self,trained_for=[1,6,7,8],defined_for=[1,6,7,8,16],bodyorder=\"v1\",n_models=16,MODEL_PATH=None \\\n",
    "                 ,HYPERS_PATH=None):\n",
    "        \n",
    "        \"\"\"initializes model by loading sklearn models,\n",
    "           bodyorder hyperparameter is ignored when choosing own architecture\n",
    "        \"\"\"\n",
    "        \n",
    "        self.species = trained_for\n",
    "        self.defined = defined_for\n",
    "\n",
    "        self.models = {k:[] for k in trained_for}\n",
    "        self.hypers = {k:None for k in trained_for}\n",
    "        \n",
    "        self._MODEL_PATH = self.DEFAULT_MODEL_PATH[bodyorder] if MODEL_PATH is None else MODEL_PATH\n",
    "        self._HYPERS_PATH = self.DEFAULT_HYPERS_PATH[bodyorder] if HYPERS_PATH is None else HYPERS_PATH\n",
    "        \n",
    "        \n",
    "        for specie in trained_for:\n",
    "            \n",
    "            with open(self._HYPERS_PATH.format(specie),\"r\") as fg:\n",
    "                hypers = json.load(fg)\n",
    "            \n",
    "            self.hypers[specie] = hypers\n",
    "            \n",
    "            for n in range(n_models):\n",
    "                model = joblib.load(self._MODEL_PATH.format(specie,n))\n",
    "                self.models[specie].append(model)\n",
    "        \n",
    "    \n",
    "    def predict(self,frames,predict_for=None,output=\"average\"):\n",
    "        \n",
    "        #assuming wrapped frames\n",
    "        results = {}\n",
    "        atomic_numbers = []\n",
    "        \n",
    "        is_single_frame = isinstance(frames,ase.atoms.Atoms)\n",
    "        \n",
    "        if is_single_frame:\n",
    "            atomic_numbers = frames.numbers\n",
    "        else:\n",
    "            for frame in frames:\n",
    "                atomic_numbers.append(frame.numbers)\n",
    "            \n",
    "        \n",
    "        atomic_numbers = np.hstack(atomic_numbers)\n",
    "        atomic_species = np.unique(atomic_numbers)\n",
    "        \n",
    "        for specie in atomic_species:\n",
    "            if specie not in self.defined:\n",
    "                raise NotImplementedError(\"Model not defined for specie {}\".format(specie))            \n",
    "        \n",
    "        if predict_for is None:\n",
    "            predict_for = self.species\n",
    "            \n",
    "        for specie in predict_for:\n",
    "            if specie not in self.species:\n",
    "                raise NotImplementedError(\"Model not trained for specie {}\".format(specie))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #avoids completely masked frames for rascal\n",
    "\n",
    "            \n",
    "        predict_for = np.intersect1d(atomic_species,predict_for)\n",
    "        predict_for = [int(specie) for specie in predict_for]\n",
    "                    \n",
    "        for specie in predict_for:\n",
    "            if is_single_frame:\n",
    "                frames.arrays.pop(\"center_atoms_mask\",None)\n",
    "                mask_center_atoms_by_species(frames,species_select=[specie])\n",
    "            else:\n",
    "                for frame in frames: \n",
    "                    frame.arrays.pop(\"center_atoms_mask\",None)\n",
    "                    mask_center_atoms_by_species(frame,species_select=[specie])\n",
    "            \n",
    "\n",
    "            if is_single_frame: \n",
    "                soap = SOAP(**self.hypers[specie])\n",
    "                Xpredict = soap.transform(frames).get_features(soap)\n",
    "            else:\n",
    "                Xpredict = get_features_in_parallel(frames,SOAP,self.hypers[specie])\n",
    "            predictions = []\n",
    "            \n",
    "            for model in self.models[specie]:\n",
    "                \n",
    "                Y_predict = model.predict(Xpredict)\n",
    "                predictions.append(Y_predict)\n",
    "            \n",
    "            results[specie] = np.vstack(predictions).T\n",
    "            \n",
    "            print(results[specie].shape)\n",
    "            if output == \"average\":\n",
    "                average = np.mean(results[specie],axis=1)\n",
    "                variance = np.var(results[specie],axis=1)\n",
    "                results[specie] = np.vstack([average,variance]).T\n",
    "            elif output == \"raw\":\n",
    "                continue\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "            #quick test to check whether copying in scaler worked\n",
    "            #print(np.allclose(Xpredict,get_features_in_parallel(frames,SOAP,self.hypers[specie])))\n",
    "        \n",
    "        return results\n",
    "        #gen feat\n",
    "        \n",
    "        #scale feat\n",
    "        #if scaling is False: skip\n",
    "        #\n",
    "        #inverse_scale predictions\n",
    "        #if inverse_scale is false: skip\n",
    "        #\n",
    "        #check option, return full predictions or average and variance\n",
    "        #return framewise, or full ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "819da2b8-1b99-469c-8321-73ed0f5559e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = ShiftMLRR(bodyorder=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "7f8ece17-5ae1-4815-9ab9-02ce9df41afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35289, 16)\n",
      "(31446, 16)\n",
      "(3367, 16)\n",
      "(6346, 16)\n"
     ]
    }
   ],
   "source": [
    "out = combined.predict(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5a0fb0bc-4e85-4558-91d3-e1b192fba743",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#frames = read(\"../../make_tensor_data/test_tensor/CSD-500+104-7_shift_tensors.xyz\",index=\":\",format=\"extxyz\")\n",
    "frames = read(\"../../../COSMO_project/make_tensor_data/test_tensor/CSD-500+104-7_shift_tensors.xyz\",index=\":\",format=\"extxyz\")\n",
    "tmp = []\n",
    "\n",
    "for frame in frames:\n",
    "    numbers = np.unique(frame.numbers)\n",
    "    \n",
    "    defined = True\n",
    "    for number in numbers:\n",
    "        if number not in [1,6,7,8,16]:\n",
    "            defined = False\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    if defined:\n",
    "        tmp.append(frame)\n",
    "\n",
    "frames = tmp\n",
    "        \n",
    "results = {}\n",
    "for specie in [1,6,7,8]:\n",
    "    tmp = []\n",
    "    for frame in frames:\n",
    "        mask_center_atoms_by_species(frame,species_select=[specie])\n",
    "        tmp.append(frame.arrays[\"cs_iso\"][frame.arrays[\"center_atoms_mask\"]])\n",
    "        del frame.arrays[\"center_atoms_mask\"]\n",
    "    results[specie] = np.hstack(tmp)   \n",
    "for frame in frames: frame.wrap(eps=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "ab713151-d4f3-4bc7-a479-8cbcee257232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37656, 2)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d79c942a-e264-42a0-b65a-2a2f4ec7c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cff0ff39-4726-4ca8-95d2-2d4be33bec0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         479318 function calls (471685 primitive calls) in 43.148 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.168    0.168   43.148   43.148 1806068984.py:115(predict)\n",
      "       64    0.000    0.000   13.269    0.207 1806068984.py:14(forward)\n",
      "        1    0.000    0.000    0.000    0.000 1806068984.py:149(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_1d)\n",
      "        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_2d)\n",
      "       14    0.000    0.000    0.488    0.035 <__array_function__ internals>:2(concatenate)\n",
      "        5    0.000    0.000    0.008    0.002 <__array_function__ internals>:2(hstack)\n",
      "     4776    0.002    0.000    0.033    0.000 <__array_function__ internals>:2(in1d)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(intersect1d)\n",
      "     4776    0.002    0.000    0.075    0.000 <__array_function__ internals>:2(isin)\n",
      "       64    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(may_share_memory)\n",
      "        4    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(mean)\n",
      "       64    0.000    0.000    3.037    0.047 <__array_function__ internals>:2(sum)\n",
      "        3    0.000    0.000    0.003    0.001 <__array_function__ internals>:2(unique)\n",
      "        4    0.000    0.000    0.006    0.001 <__array_function__ internals>:2(var)\n",
      "        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(vstack)\n",
      "       32    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "      108    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:389(parent)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "       64    0.000    0.000    0.000    0.000 __init__.py:31(__get__)\n",
      "       32    0.000    0.000    0.001    0.000 __init__.py:36(__init__)\n",
      "       32    0.000    0.000    0.003    0.000 __init__.py:43(start)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:8(_make_name)\n",
      "        8    0.000    0.000    0.000    0.000 _bootlocale.py:33(getpreferredencoding)\n",
      "        4    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
      "       64    0.000    0.000    0.000    0.000 _config.py:16(_get_threadlocal_config)\n",
      "       64    0.000    0.000    0.000    0.000 _config.py:24(get_config)\n",
      "       64    9.856    0.154   20.244    0.316 _data.py:177(transform)\n",
      "       64    0.005    0.000    0.006    0.000 _data.py:213(inverse_transform)\n",
      "       64    0.000    0.000    0.000    0.000 _jit_internal.py:957(is_scripting)\n",
      "        4    0.000    0.000    0.002    0.000 _methods.py:162(_mean)\n",
      "        4    0.003    0.001    0.006    0.001 _methods.py:195(_var)\n",
      "        8    0.000    0.000    0.000    0.000 _methods.py:66(_count_reduce_items)\n",
      "       64    0.000    0.000    0.000    0.000 _parallel_backends.py:124(get_nested_backend)\n",
      "        8    0.000    0.000    0.000    0.000 _parallel_backends.py:137(retrieval_context)\n",
      "        4    0.000    0.000    0.001    0.000 _parallel_backends.py:227(effective_n_jobs)\n",
      "        4    0.000    0.000    0.004    0.001 _parallel_backends.py:239(terminate)\n",
      "       64    0.000    0.000    0.006    0.000 _parallel_backends.py:250(apply_async)\n",
      "       68    0.000    0.000    0.000    0.000 _parallel_backends.py:34(__init__)\n",
      "        4    0.000    0.000    0.001    0.000 _parallel_backends.py:389(configure)\n",
      "       64    0.000    0.000    0.005    0.000 _parallel_backends.py:400(_get_pool)\n",
      "       64    0.000    0.000    0.000    0.000 _parallel_backends.py:590(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 _parallel_backends.py:80(start_call)\n",
      "        4    0.000    0.000    0.000    0.000 _parallel_backends.py:83(stop_call)\n",
      "       68    0.000    0.000    0.000    0.000 _parallel_backends.py:89(compute_batch_size)\n",
      "       26    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)\n",
      "       44    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
      "       64    0.000    0.000    0.000    0.000 abc.py:100(__subclasscheck__)\n",
      "       68    0.000    0.000    0.001    0.000 abc.py:96(__instancecheck__)\n",
      "       32    0.000    0.000    0.126    0.004 activation.py:348(forward)\n",
      "       32    0.000    0.000    0.547    0.017 activation.py:805(forward)\n",
      "        3    0.000    0.000    0.000    0.000 arraysetops.py:125(_unpack_tuple)\n",
      "        3    0.000    0.000    0.000    0.000 arraysetops.py:133(_unique_dispatcher)\n",
      "        3    0.000    0.000    0.003    0.001 arraysetops.py:138(unique)\n",
      "        3    0.000    0.000    0.003    0.001 arraysetops.py:320(_unique1d)\n",
      "        1    0.000    0.000    0.000    0.000 arraysetops.py:364(_intersect1d_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 arraysetops.py:369(intersect1d)\n",
      "     4776    0.000    0.000    0.000    0.000 arraysetops.py:515(_in1d_dispatcher)\n",
      "     4776    0.019    0.000    0.028    0.000 arraysetops.py:519(in1d)\n",
      "     4776    0.001    0.000    0.001    0.000 arraysetops.py:636(_isin_dispatcher)\n",
      "     4776    0.004    0.000    0.070    0.000 arraysetops.py:640(isin)\n",
      "     2985    0.001    0.000    0.001    0.000 atoms.py:1938(_get_atomic_numbers)\n",
      "     2388    0.001    0.000    0.003    0.000 atoms.py:258(symbols)\n",
      "     2388    0.001    0.000    0.005    0.000 atoms.py:522(get_atomic_numbers)\n",
      "     2388    0.022    0.000    0.060    0.000 atoms.py:526(get_chemical_symbols)\n",
      "     2388    0.001    0.000    0.001    0.000 atoms.py:958(__len__)\n",
      "       64    0.000    0.000    0.000    0.000 base.py:1205(isspmatrix)\n",
      "       64    0.000    0.000    0.001    0.000 base.py:359(_check_n_features)\n",
      "       64    0.000    0.000    0.000    0.000 base.py:405(_check_feature_names)\n",
      "       64    0.001    0.000   10.387    0.162 base.py:495(_validate_data)\n",
      "        8    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 codecs.py:319(decode)\n",
      "        8    0.000    0.000    0.000    0.000 connection.py:117(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
      "       12    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)\n",
      "       12    0.000    0.000    0.000    0.000 connection.py:142(_check_writable)\n",
      "       12    0.000    0.000    0.000    0.000 connection.py:181(send_bytes)\n",
      "        8    0.000    0.000    0.000    0.000 connection.py:360(_close)\n",
      "       12    0.000    0.000    0.000    0.000 connection.py:365(_send)\n",
      "       12    0.000    0.000    0.000    0.000 connection.py:390(_send_bytes)\n",
      "        4    0.000    0.000    0.000    0.000 connection.py:516(Pipe)\n",
      "       64    0.000    0.000    0.000    0.000 container.py:131(__iter__)\n",
      "       64    0.002    0.000   13.268    0.207 container.py:139(forward)\n",
      "        4    0.000    0.000    0.001    0.000 context.py:110(SimpleQueue)\n",
      "        4    0.000    0.000    0.001    0.000 context.py:110(cpu_count)\n",
      "        4    0.000    0.000    0.001    0.000 context.py:169(_cpu_count_user)\n",
      "       12    0.000    0.000    0.000    0.000 context.py:187(get_context)\n",
      "        8    0.000    0.000    0.000    0.000 context.py:197(get_start_method)\n",
      "        8    0.000    0.000    0.000    0.000 context.py:233(get_context)\n",
      "        4    0.000    0.000    0.000    0.000 context.py:41(cpu_count)\n",
      "        8    0.000    0.000    0.001    0.000 context.py:65(Lock)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:108(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:117(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:238(helper)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:82(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 disk.py:42(memstr_to_bytes)\n",
      "       64    0.000    0.000    3.038    0.047 extmath.py:869(_safe_accumulator_op)\n",
      "       64    0.000    0.000    0.001    0.000 flatten.py:41(forward)\n",
      "       64    0.000    0.000    0.000    0.000 fromnumeric.py:2118(_sum_dispatcher)\n",
      "       64    0.000    0.000    3.037    0.047 fromnumeric.py:2123(sum)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:3317(_mean_dispatcher)\n",
      "        4    0.000    0.000    0.002    0.000 fromnumeric.py:3322(mean)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:3585(_var_dispatcher)\n",
      "        4    0.000    0.000    0.006    0.001 fromnumeric.py:3590(var)\n",
      "       64    0.000    0.000    3.037    0.047 fromnumeric.py:69(_wrapreduction)\n",
      "       64    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "      128    0.001    0.000   12.217    0.095 functional.py:1832(linear)\n",
      "       64    0.001    0.000    0.371    0.006 functional.py:2332(layer_norm)\n",
      "       64    0.000    0.000    0.000    0.000 functools.py:34(update_wrapper)\n",
      "       64    0.000    0.000    0.000    0.000 functools.py:64(wraps)\n",
      "        8    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
      "       64    0.001    0.000    0.001    0.000 grad_mode.py:119(__init__)\n",
      "       64    0.000    0.000    0.001    0.000 grad_mode.py:124(__enter__)\n",
      "       64    0.000    0.000    0.001    0.000 grad_mode.py:128(__exit__)\n",
      "      128    0.000    0.000    0.001    0.000 grad_mode.py:213(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 helpers.py:4(grouper)\n",
      "      128    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
      "      128    0.001    0.000   12.218    0.095 linear.py:102(forward)\n",
      "        4    0.000    0.000    0.000    0.000 logger.py:23(_squeeze_time)\n",
      "        4    0.000    0.000    0.000    0.000 logger.py:39(short_format_time)\n",
      "   512/64    0.003    0.000   13.271    0.207 module.py:1096(_call_impl)\n",
      "      576    0.001    0.000    0.001    0.000 module.py:1164(__getattr__)\n",
      "       64    0.000    0.000    0.000    0.000 multiarray.py:1368(may_share_memory)\n",
      "       14    0.000    0.000    0.000    0.000 multiarray.py:148(concatenate)\n",
      "       64    0.001    0.000    0.371    0.006 normalization.py:188(forward)\n",
      "      128    0.000    0.000    0.000    0.000 numerictypes.py:284(issubclass_)\n",
      "       64    0.000    0.000    0.000    0.000 numerictypes.py:358(issubdtype)\n",
      "        4    0.000    0.000    0.000    0.000 os.py:670(__getitem__)\n",
      "        4    0.000    0.000    0.000    0.000 os.py:748(encode)\n",
      "        4    0.000    0.000    9.276    2.319 parallel.py:13(get_features_in_parallel)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:184(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:216(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:219(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:222(unregister)\n",
      "       64    0.000    0.000    0.001    0.000 parallel.py:23(<genexpr>)\n",
      "       64    0.000    0.000    0.000    0.000 parallel.py:245(__init__)\n",
      "      192    0.000    0.000    0.000    0.000 parallel.py:275(__len__)\n",
      "       64    0.000    0.000    0.000    0.000 parallel.py:321(delayed)\n",
      "       64    0.000    0.000    0.000    0.000 parallel.py:324(delayed_function)\n",
      "       64    0.000    0.000    0.000    0.000 parallel.py:345(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:639(__init__)\n",
      "        4    0.000    0.000    0.001    0.000 parallel.py:732(_initialize_backend)\n",
      "        4    0.000    0.000    0.004    0.001 parallel.py:757(_terminate_backend)\n",
      "        4    0.000    0.000    0.000    0.000 parallel.py:76(get_active_backend)\n",
      "       64    0.000    0.000    0.006    0.000 parallel.py:761(_dispatch)\n",
      "       68    0.000    0.000    0.008    0.000 parallel.py:798(dispatch_one_batch)\n",
      "        8    0.000    0.000    0.000    0.000 parallel.py:864(_print)\n",
      "        4    0.001    0.000    8.782    2.196 parallel.py:920(retrieve)\n",
      "        4    0.000    0.000    8.795    2.199 parallel.py:960(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 pool.py:157(__init__)\n",
      "        4    0.000    0.000    0.005    0.001 pool.py:183(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 pool.py:263(__del__)\n",
      "        4    0.000    0.000    0.003    0.001 pool.py:302(_repopulate_pool)\n",
      "        4    0.000    0.000    0.003    0.001 pool.py:311(_repopulate_pool_static)\n",
      "       64    0.000    0.000    0.000    0.000 pool.py:348(_check_running)\n",
      "       64    0.000    0.000    0.000    0.000 pool.py:450(apply_async)\n",
      "        4    0.000    0.000    0.001    0.000 pool.py:644(close)\n",
      "        4    0.000    0.000    0.002    0.000 pool.py:651(terminate)\n",
      "        4    0.000    0.000    0.002    0.000 pool.py:677(_terminate_pool)\n",
      "       64    0.000    0.000    0.000    0.000 pool.py:744(__init__)\n",
      "       96    0.000    0.000    0.000    0.000 pool.py:753(ready)\n",
      "       96    0.000    0.000    8.780    0.091 pool.py:761(wait)\n",
      "       96    0.000    0.000    8.781    0.091 pool.py:764(get)\n",
      "       32    0.000    0.000    0.001    0.000 pool.py:919(Process)\n",
      "        4    0.000    0.000    0.005    0.001 pool.py:924(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 pool.py:927(_setup_queues)\n",
      "        4    0.000    0.000    0.000    0.000 pool.py:933(_get_sentinels)\n",
      "        4    0.000    0.000    0.000    0.000 pool.py:940(_help_stuff_finish)\n",
      "       64    0.000    0.000    0.000    0.000 queue.py:121(put)\n",
      "       76    0.000    0.000    0.000    0.000 queue.py:153(get)\n",
      "        4    0.000    0.000    0.000    0.000 queue.py:205(_init)\n",
      "       76    0.000    0.000    0.000    0.000 queue.py:208(_qsize)\n",
      "       64    0.000    0.000    0.000    0.000 queue.py:212(_put)\n",
      "       64    0.000    0.000    0.000    0.000 queue.py:216(_get)\n",
      "        4    0.000    0.000    0.000    0.000 queue.py:33(__init__)\n",
      "        4    0.000    0.000    0.001    0.000 queues.py:334(__init__)\n",
      "       12    0.000    0.000    0.001    0.000 queues.py:360(put)\n",
      "       64    0.000    0.000    0.000    0.000 random.py:250(_randbelow_with_getrandbits)\n",
      "       64    0.000    0.000    0.000    0.000 random.py:285(choice)\n",
      "       12    0.000    0.000    0.000    0.000 reduction.py:38(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 reduction.py:48(dumps)\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "        9    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        9    0.000    0.000    0.000    0.000 shape_base.py:218(_vhstack_dispatcher)\n",
      "        4    0.000    0.000    0.000    0.000 shape_base.py:222(vstack)\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:23(atleast_1d)\n",
      "        5    0.000    0.000    0.008    0.002 shape_base.py:285(hstack)\n",
      "        4    0.000    0.000    0.000    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        4    0.000    0.000    0.000    0.000 shape_base.py:81(atleast_2d)\n",
      "     2388    0.012    0.000    0.159    0.000 structure_manager.py:399(mask_center_atoms_by_species)\n",
      "     2388    0.001    0.000    0.001    0.000 structure_manager.py:436(<lambda>)\n",
      "     2388    0.000    0.000    0.001    0.000 structure_manager.py:439(<lambda>)\n",
      "       64    0.000    0.000   13.270    0.207 swa_utils.py:100(forward)\n",
      "     2388    0.001    0.000    0.001    0.000 symbols.py:58(__init__)\n",
      "   310260    0.033    0.000    0.033    0.000 symbols.py:78(__iter__)\n",
      "     4776    0.001    0.000    0.001    0.000 symbols.py:89(__len__)\n",
      "        8    0.000    0.000    0.001    0.000 synchronize.py:161(__init__)\n",
      "        8    0.000    0.000    0.001    0.000 synchronize.py:50(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
      "       12    0.000    0.000    0.001    0.000 synchronize.py:94(__enter__)\n",
      "       12    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 tempfile.py:133(rng)\n",
      "        8    0.000    0.000    0.000    0.000 tempfile.py:144(__next__)\n",
      "        8    0.000    0.000    0.000    0.000 tempfile.py:147(<listcomp>)\n",
      "       16    0.000    0.000    0.001    0.000 threading.py:1017(_wait_for_tstate_lock)\n",
      "       32    0.000    0.000    0.000    0.000 threading.py:1031(name)\n",
      "       32    0.000    0.000    0.000    0.000 threading.py:1042(name)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1071(is_alive)\n",
      "       56    0.000    0.000    0.000    0.000 threading.py:1095(daemon)\n",
      "       44    0.000    0.000    0.000    0.000 threading.py:1110(daemon)\n",
      "       44    0.000    0.000    0.000    0.000 threading.py:1177(_make_invoke_excepthook)\n",
      "      132    0.000    0.000    0.000    0.000 threading.py:1306(current_thread)\n",
      "      120    0.000    0.000    0.000    0.000 threading.py:222(__init__)\n",
      "      280    0.000    0.000    0.000    0.000 threading.py:246(__enter__)\n",
      "      280    0.000    0.000    0.000    0.000 threading.py:249(__exit__)\n",
      "       78    0.000    0.000    0.000    0.000 threading.py:255(_release_save)\n",
      "       78    0.000    0.000    0.000    0.000 threading.py:258(_acquire_restore)\n",
      "      206    0.000    0.000    0.000    0.000 threading.py:261(_is_owned)\n",
      "       78    0.001    0.000    8.782    0.113 threading.py:270(wait)\n",
      "      128    0.000    0.000    0.000    0.000 threading.py:341(notify)\n",
      "      108    0.000    0.000    0.000    0.000 threading.py:505(__init__)\n",
      "      200    0.000    0.000    0.000    0.000 threading.py:513(is_set)\n",
      "      140    0.000    0.000    8.783    0.063 threading.py:540(wait)\n",
      "       44    0.000    0.000    0.000    0.000 threading.py:734(_newname)\n",
      "       44    0.000    0.000    0.001    0.000 threading.py:761(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:81(RLock)\n",
      "       44    0.000    0.000    0.003    0.000 threading.py:834(start)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:944(_stop)\n",
      "       12    0.000    0.000    0.001    0.000 threading.py:979(join)\n",
      "        8    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)\n",
      "        4    0.000    0.000    0.000    0.000 util.py:186(__init__)\n",
      "        4    0.000    0.000    0.002    0.000 util.py:205(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
      "       68    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
      "        4    0.000    0.000    0.000    0.000 uuid.py:132(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 uuid.py:327(hex)\n",
      "        4    0.000    0.000    0.000    0.000 uuid.py:780(uuid4)\n",
      "      128    0.001    0.000    0.002    0.000 validation.py:1153(check_is_fitted)\n",
      "      128    0.000    0.000    0.000    0.000 validation.py:1213(<listcomp>)\n",
      "       64    0.000    0.000    0.000    0.000 validation.py:1653(_get_feature_names)\n",
      "       64    0.001    0.000    0.001    0.000 validation.py:201(_num_features)\n",
      "       64    0.001    0.000    0.002    0.000 validation.py:254(_num_samples)\n",
      "       64    0.000    0.000    0.000    0.000 validation.py:484(_ensure_no_complex_data)\n",
      "       64    0.002    0.000   10.385    0.162 validation.py:494(check_array)\n",
      "       64    0.002    0.000    3.041    0.048 validation.py:90(_assert_all_finite)\n",
      "       64    0.000    0.000    0.001    0.000 warnings.py:165(simplefilter)\n",
      "       64    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "       64    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
      "       64    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
      "       64    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 weakref.py:103(remove)\n",
      "        8    0.000    0.000    0.000    0.000 weakref.py:159(__setitem__)\n",
      "        8    0.000    0.000    0.000    0.000 weakref.py:323(__new__)\n",
      "        8    0.000    0.000    0.000    0.000 weakref.py:328(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 weakref.py:343(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 weakref.py:345(remove)\n",
      "       32    0.000    0.000    0.000    0.000 weakref.py:395(__setitem__)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55f5d3a1be20}\n",
      "       68    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "     9552    0.002    0.000    0.004    0.000 {built-in method _functools.reduce}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
      "      190    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "      132    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       44    0.001    0.000    0.001    0.000 {built-in method _thread.start_new_thread}\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
      "        1    0.000    0.000   43.155   43.155 {built-in method builtins.exec}\n",
      "      764    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "     1381    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "     5822    0.001    0.000    0.002    0.000 {built-in method builtins.isinstance}\n",
      "      208    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "       72    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "24735/22347    0.003    0.000    0.004    0.000 {built-in method builtins.len}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "       92    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "      320    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "       64    0.001    0.000    0.001    0.000 {built-in method from_numpy}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "       64    0.370    0.006    0.370    0.006 {built-in method layer_norm}\n",
      "       64    7.338    0.115    7.338    0.115 {built-in method numpy.array}\n",
      "      753    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "    16780    0.035    0.000    0.035    0.000 {built-in method numpy.asarray}\n",
      "9724/4927    0.493    0.000    3.609    0.001 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "     7164    0.004    0.000    0.004    0.000 {built-in method numpy.zeros}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.cpu_count}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.sched_getaffinity}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method posix.write}\n",
      "       32    0.126    0.004    0.126    0.004 {built-in method tanh}\n",
      "       72    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "      512    0.001    0.000    0.001    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "      128   12.216    0.095   12.216    0.095 {built-in method torch._C._nn.linear}\n",
      "       32    0.547    0.017    0.547    0.017 {built-in method torch._C._nn.softplus}\n",
      "      128    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "      192    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}\n",
      "       12    0.001    0.000    0.001    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "      280    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "      280    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "      456    8.782    0.019    8.782    0.019 {method 'acquire' of '_thread.lock' objects}\n",
      "       44    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "      142    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1362    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "       76    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "     2388    0.004    0.000    0.004    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       26    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       96    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "       64    0.001    0.000    0.001    0.000 {method 'flatten' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'get' of '_queue.SimpleQueue' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "      104    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "      128    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "     2388    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
      "       96    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'put' of '_queue.SimpleQueue' objects}\n",
      "     9552    0.002    0.000    0.002    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
      "       76    3.040    0.040    3.040    0.040 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       90    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "     4840    0.002    0.000    0.002    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      108    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        4    0.003    0.001    0.003    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       76    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"combined.predict(frames)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "15c93755-0e5f-4e0d-99c9-33f365f8a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2157128969044495\n",
      "9.267273088469878\n",
      "36.39220933978026\n",
      "52.414795798181224\n"
     ]
    }
   ],
   "source": [
    "for specie in [1,6,7,8]:\n",
    "    print(mean_squared_error(out[specie][:,0],results[specie],squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5e07fd65-c8f6-44e1-9acd-dd79dac59d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = ShiftMLNN(bodyorder=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9b2a0590-be55-42c0-b627-3274582a0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- transform 9.963484048843384 seconds-----\n",
      "---torch 13.166052103042603 seconds ---\n",
      "---feat 9.179221868515015 seconds ---\n",
      "---structure loops 0.1090242862701416 seconds ---\n",
      "---inverse 0.007536172866821289 seconds ---\n"
     ]
    }
   ],
   "source": [
    "out = combined.predict(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "97817b2c-7cb1-4dc4-be51-1aab59353364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31446, 2)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b43e27eb-f2fb-4672-bb4e-481644739fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = ShiftMLNN(bodyorder=\"v2\")\n",
    "#out = combined.predict(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "3f8d8cad-5adf-412a-8cec-94a2fc9107ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22418/1172997345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22418/1050031384.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, frames, predict_for, output)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"average\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecie\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecie\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecie\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/ssd/scratch/kellner/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3438\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3440\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3441\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd/scratch/kellner/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of empty slice.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd/scratch/kellner/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "out = combined.predict(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "30c5e187-9bbc-4b22-9b98-8b2f7a158503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101512,)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[specie][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a311d31a-96ee-4ed2-a5e4-7a590b7c2a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.730138955385111\n",
      "18.465306167014948\n",
      "53.848914359413676\n",
      "82.30760589322293\n"
     ]
    }
   ],
   "source": [
    "for specie in [1,6,7,8]:\n",
    "    print(mean_squared_error(out[specie][:,0],results[specie],squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "4ac878c8-3886-49fe-80ac-37e4e0a12a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "6d0ecb41-c1c9-4ae9-949d-7996d75c9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.01831426327777"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specie = 6\n",
    "np.abs(mean_squared_error(out[specie][:,0],results[specie],squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7fbe78f8-f581-4c60-b90d-c96f9bfe8514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5514.088532382175"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(out[specie][:,0]-results[specie]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "e9a37580-fba0-4a01-8c74-d8784857740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.01831426327777"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(mean_squared_error(out[specie][:,0],results[specie],squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "1056f49b-2488-4d06-ade1-05197846a407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.72290580901381"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results[specie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "d94bcb3b-6482-43bd-8091-ac14a4415c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"6_hypers.json\",\"r\") as fg:\n",
    "    hypers = json.load(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "b95570ca-f750-484f-b19a-aad0aa706ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers[\"global_species\"] = [ 1,  6,  7,  8,  9, 11, 12, 15, 16, 17, 19, 20, 35, 53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "f591a2e1-988f-4357-b46e-cda73ce3bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soap = SOAP(**hypers)\n",
    "Xpredict = soap.transform(frames[0]).get_features(soap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5d5a4359-9c30-4a92-8398-261704d9ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 26460)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "5db48784-07e2-4da1-8d3c-db7c2b70c34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.38015334431056"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(out[specie][:,0],results[specie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "80bac71b-e7a9-47ab-8277-6ec65655bfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out[specie][:,0]-results[specie])>80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "48f2ddc4-f1bb-4ddc-b2cf-508f3d72c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "specie = 6\n",
    "_ = plt.hist(np.abs(out[specie][:,0]-results[specie]),bins=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d86a6e6c-9235-4170-82a9-89d79444b3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.76909048612231"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(out[specie][:,0]-results[specie]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e4404360-a5dc-40db-8cab-d27f79daa4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "9b6f10df-ac48-470b-845d-ee4772f1c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = read(\"../../../COSMO_project/Shiftml2/CSD-10k_fps_training_relax_w_shifts.xyz\",index=\":\",format=\"extxyz\")\n",
    "tmp = []\n",
    "\n",
    "for frame in frames:\n",
    "    tmp.append(frame.numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbafb0-6d08-4426-b2e7-e76eefef02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "4df2d1f6-c0f9-4792-ab51-879ed1da8c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.84"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14**2/5**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "bfc9d5e1-a561-4a1b-9ee8-2168b5598c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6,  7,  8,  9, 11, 12, 15, 16, 17, 19, 20, 35, 53])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.hstack(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "cb1d9718-4515-4217-8044-0d9cc9fa6005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.hstack(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "e47cb6e0-41e7-4383-8ee1-ea8b5d321ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4060"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "fd1b8d14-b3e4-47ff-aaca-ebde584bbe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  6,  6,  6,  6,  1,  1,  1,  1,  1,  1,  1,  1,  6,  6,\n",
       "        6,  6,  1,  1,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  6,  6,  6,  6,  1,  1,  1,  1,  1,  1,  1,  1,  6,  6,\n",
       "        6,  6,  1,  1,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[1030].numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "06011315-c619-4aa1-b8a1-8b2fd619128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./scaler_features_8_model_no_0_float64_opt.pkl\",\"rb\") as fg:\n",
    "    scaler = pickle.load(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0064bdcb-f60b-42ca-8a5f-29f7e7bea8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.95668486e-06, 7.10006291e-07, 7.21640096e-07, ...,\n",
       "       3.47400628e-10, 3.83742881e-10, 3.92947223e-10])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5297b9da-6d9e-4e36-8a90-e4ad69a10136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46581.38230758, 46581.4403797 , 46581.43983779, ...,\n",
       "        46581.47343666, 46581.47343497, 46581.47343454],\n",
       "       [46581.38230758, 46581.4403797 , 46581.43983779, ...,\n",
       "        46581.47343666, 46581.47343497, 46581.47343454],\n",
       "       [46581.38230758, 46581.4403797 , 46581.43983779, ...,\n",
       "        46581.47343666, 46581.47343497, 46581.47343454],\n",
       "       ...,\n",
       "       [46581.38230758, 46581.4403797 , 46581.43983779, ...,\n",
       "        46581.47343666, 46581.47343497, 46581.47343454],\n",
       "       [46581.38230758, 46581.4403797 , 46581.43983779, ...,\n",
       "        46581.47343666, 46581.47343497, 46581.47343454],\n",
       "       [46581.38230758, 46581.4403797 , 46581.43983779, ...,\n",
       "        46581.47343666, 46581.47343497, 46581.47343454]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(torch.ones(100,3780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f04e9f44-4d08-411e-b5e1-b64d55a86874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "119acb09-61f9-44b1-a9ee-9978fa6c0496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d([1,7,8,9],[7,8,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c6e405a0-0da0-4471-b2cb-319e81f2883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(frames[0],ase.atoms.Atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2d7d1cfd-baef-4900-a0bb-4abe44af3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = type(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5b8da3f3-bfb9-4177-9cdb-a9c4b6ec425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dcb30aaf-5bcb-4d5c-9456-109838d74b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "042be97d-6880-4680-aff1-abfbabeff549",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  192.,   240.,   580.,   647.,  1936., 16768., 15437., 18662.,\n",
       "        30156.,  6550.]),\n",
       " array([11.96196233, 13.9296232 , 15.89728406, 17.86494493, 19.83260579,\n",
       "        21.80026666, 23.76792752, 25.73558838, 27.70324925, 29.67091011,\n",
       "        31.63857098]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "deb5fdab-37f0-4dd1-8988-88f9de308fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c64a07fe-5bb0-4b74-b95a-fa06bc69f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2fca7011-051d-4dff-a8cd-dd1bbe3d8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693687672065885\n",
      "5.766577975730453\n",
      "16.0914214643406\n",
      "20.395912127559154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ac2f387b-5528-44de-8292-718762d12951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aee2729e-6f16-4f97-9174-0b28e6d7574a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'atomic_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22418/1724220523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22418/3190072185.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0matomic_number\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'atomic_number' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba859090-05e0-4449-b3cb-cabb5856ceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "1 1 1\n",
      "2 2 2\n",
      "3 3 3\n",
      "4 4 4\n",
      "5 5 5\n",
      "6 6 6\n",
      "7 7 7\n",
      "8 8 8\n"
     ]
    }
   ],
   "source": [
    "for a,b,c, in zip(range(0,9),range(0,9),range(0,9)): print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a29f4-6294-4de6-8bbb-32df46c4b041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "063e6daa-8ac0-40e2-941f-774aa4564daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(n_hidden=16,activation=nn.ReLU,num_input=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b89976a2-5185-4960-95cc-b0d24c2473ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(\"../multi_NN_v2/large_model_7_13_float64_opt.pth\",map_location=torch.device('cpu'))\n",
    "b = {k.replace(\"module.\",\"\"):v for k,v in a.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b55061bc-422e-4456-9680-409ba83e3be4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_relu_stack.0.weight',\n",
       "              tensor([[ 1.0723e-01,  1.2103e-02,  9.1022e-02,  1.0258e-01, -5.1082e-02,\n",
       "                       -9.6621e-02,  1.4879e-02,  1.2175e-01, -3.4338e-02,  1.2814e-01,\n",
       "                       -8.8985e-02, -1.9065e-02,  1.2659e-01,  7.8106e-02, -2.1368e-02,\n",
       "                       -1.2447e-02, -3.9047e-02, -1.1719e-01,  2.6314e-02, -4.9876e-02,\n",
       "                       -9.2950e-02,  6.7280e-02,  1.2637e-01,  1.2506e-01,  6.3418e-02,\n",
       "                       -6.3661e-03, -1.0385e-01, -1.2544e-01, -2.7939e-02, -1.0927e-01,\n",
       "                        5.7022e-03,  5.9898e-02, -9.7526e-02, -9.5788e-02, -4.5331e-02,\n",
       "                       -1.1749e-01, -6.7836e-02,  6.3891e-02,  2.0629e-02,  5.7682e-02,\n",
       "                        7.1627e-02, -1.0821e-01, -2.2727e-02,  5.6475e-02,  1.2592e-02,\n",
       "                       -6.0763e-02,  4.4625e-02, -3.7383e-02, -1.0055e-01,  1.0618e-01,\n",
       "                       -2.2717e-02,  8.1898e-02, -9.2159e-02, -1.0431e-02, -2.8068e-02,\n",
       "                        8.6708e-02, -4.4156e-02, -7.7928e-02, -6.7012e-02,  2.2919e-02],\n",
       "                      [-5.4765e-02,  1.2755e-01, -1.0887e-01, -1.2495e-01,  3.4418e-02,\n",
       "                        9.5000e-02,  9.9407e-02, -6.1604e-02,  3.3483e-03, -2.3153e-02,\n",
       "                        1.1142e-01,  1.3935e-02, -6.5724e-02, -1.0293e-01, -2.7006e-02,\n",
       "                       -1.1473e-01, -6.1272e-02, -6.6833e-02,  8.4834e-02, -1.0046e-01,\n",
       "                        6.2174e-02,  9.5131e-02, -4.3568e-02, -1.1961e-01,  2.9941e-02,\n",
       "                        9.6427e-02,  1.0950e-01,  6.8362e-02,  1.9905e-02,  4.3531e-02,\n",
       "                       -3.1031e-02, -1.2493e-01, -8.2626e-02, -4.4885e-03,  7.7037e-02,\n",
       "                        2.0665e-02, -1.1206e-01, -8.5513e-02,  2.3240e-02,  4.6274e-02,\n",
       "                        7.3244e-02,  1.1970e-01, -4.3709e-02,  1.0559e-01, -3.5810e-02,\n",
       "                       -1.5004e-02, -9.4272e-02,  1.1818e-01, -1.1333e-02,  7.3925e-02,\n",
       "                        7.5881e-02,  1.1098e-01,  9.0511e-02,  5.1128e-02,  5.0552e-02,\n",
       "                        3.7104e-02, -1.1234e-01,  3.6395e-02,  3.0458e-02,  4.8600e-02],\n",
       "                      [ 4.6628e-02, -1.2634e-01,  1.1971e-01,  7.3974e-02,  5.3753e-02,\n",
       "                        1.2400e-01, -5.6617e-02, -4.7062e-02, -6.8311e-02,  4.3457e-02,\n",
       "                        2.0792e-02, -1.2779e-01, -4.5337e-02,  9.4034e-02,  5.9154e-02,\n",
       "                       -3.3250e-03, -9.1758e-02,  6.9110e-02,  8.7391e-02,  9.8901e-02,\n",
       "                        5.3449e-02,  7.5037e-02,  1.4330e-02,  1.0547e-01,  2.0314e-02,\n",
       "                        7.0827e-02, -8.4488e-02, -8.0305e-02,  9.5379e-02,  3.1571e-02,\n",
       "                       -9.5670e-02, -1.2222e-01, -3.6268e-02,  1.2698e-01,  5.7096e-02,\n",
       "                       -2.0187e-02,  1.0463e-01,  5.7121e-02, -4.6415e-02,  1.0826e-01,\n",
       "                        1.1927e-01, -3.8694e-02, -1.6930e-03, -9.4667e-02, -7.1566e-02,\n",
       "                        3.0834e-02,  1.1593e-01, -1.6646e-03,  1.7451e-02, -3.5710e-02,\n",
       "                       -8.7926e-03, -5.7370e-02, -8.1593e-02, -6.2060e-02,  1.2504e-01,\n",
       "                       -6.9941e-02,  8.2161e-03,  1.0210e-01, -1.2451e-01,  4.2854e-02],\n",
       "                      [-1.8234e-02, -1.4626e-02, -1.1264e-01,  1.8097e-02,  1.1767e-01,\n",
       "                       -5.8295e-02,  3.3256e-02, -9.8553e-02, -5.1775e-02,  1.2066e-01,\n",
       "                        7.3253e-02,  1.1598e-01,  7.3920e-02,  6.5204e-02, -3.3291e-02,\n",
       "                       -6.3050e-02, -1.1039e-01, -8.7860e-02, -5.2798e-02, -1.2700e-01,\n",
       "                       -2.5642e-02,  4.3289e-02, -7.5502e-02, -1.2394e-01, -3.0455e-02,\n",
       "                       -9.4269e-02,  5.0473e-02, -2.7956e-02,  3.7695e-02,  6.3701e-02,\n",
       "                        1.0734e-01, -1.3246e-02,  6.0358e-02,  1.5671e-02,  7.6511e-02,\n",
       "                        3.7044e-02, -3.4643e-02,  8.9540e-02, -1.2553e-01, -8.3652e-03,\n",
       "                       -1.2286e-01, -8.0812e-02, -3.3123e-02,  5.8904e-03, -1.9323e-02,\n",
       "                        9.7084e-03, -1.7552e-02, -6.7840e-02, -3.0681e-02, -6.8577e-02,\n",
       "                       -9.7442e-03, -1.0729e-01, -7.3561e-02, -9.2465e-02,  7.6499e-02,\n",
       "                       -1.1782e-01, -9.2439e-02, -9.1076e-02,  1.0623e-01, -9.8133e-02],\n",
       "                      [ 3.2864e-02,  3.8567e-02, -7.9357e-02,  7.2150e-02, -1.7110e-02,\n",
       "                       -6.6630e-02,  9.8514e-02,  8.9880e-02,  1.1261e-02, -2.0583e-02,\n",
       "                        3.3220e-02,  5.9043e-02, -1.1608e-02,  1.2174e-01,  7.5215e-02,\n",
       "                        1.7136e-02,  7.4852e-02,  6.3419e-03,  9.3938e-02,  7.3701e-02,\n",
       "                        1.6283e-02,  1.8931e-02,  7.9418e-02,  2.2321e-02,  1.2371e-01,\n",
       "                        2.9102e-02, -8.7640e-02,  1.1223e-01, -2.2754e-02,  8.2538e-02,\n",
       "                        1.1933e-01,  1.1364e-01,  3.4564e-02,  7.8755e-02,  7.8077e-02,\n",
       "                        1.1425e-01, -3.5908e-02, -5.1281e-02, -9.7808e-02,  5.6100e-02,\n",
       "                       -3.7886e-03, -1.8629e-02,  4.1847e-02,  8.8015e-02, -1.1939e-01,\n",
       "                       -1.9747e-02,  8.4804e-02,  1.1933e-01,  2.0550e-02, -2.0150e-02,\n",
       "                       -1.2845e-01,  4.1101e-02,  2.1534e-02,  9.8877e-02,  5.5343e-02,\n",
       "                        5.7792e-02, -1.0336e-02,  5.6151e-02,  7.7931e-02,  3.2024e-02],\n",
       "                      [-2.9054e-02,  1.2677e-01,  3.0212e-02,  1.2874e-01,  6.4915e-02,\n",
       "                       -7.8550e-02,  5.0365e-02, -4.1944e-02, -2.2227e-02,  6.5528e-02,\n",
       "                       -1.2606e-01, -7.9593e-03, -1.2731e-01, -1.0852e-01, -4.0647e-02,\n",
       "                        1.7359e-02,  8.7734e-02, -4.2357e-02, -2.5250e-02, -5.1947e-02,\n",
       "                       -3.5957e-03, -8.7537e-02, -2.8281e-02,  1.0550e-01,  4.4579e-02,\n",
       "                        8.7554e-02, -1.5711e-02, -3.8123e-02,  9.0987e-02,  4.0220e-02,\n",
       "                       -2.9058e-02,  2.0465e-02,  5.3854e-03,  5.9049e-02,  1.1964e-02,\n",
       "                       -9.9214e-02, -1.2752e-01, -8.7504e-02, -1.2377e-01,  7.2249e-02,\n",
       "                        1.6482e-02, -3.7221e-02,  4.1894e-03, -1.1908e-01,  1.2601e-01,\n",
       "                        9.1319e-02,  1.0842e-01,  8.7825e-03,  1.1858e-01,  1.1204e-01,\n",
       "                        2.4858e-02, -9.2092e-02,  1.2908e-02, -4.0381e-02,  4.3724e-02,\n",
       "                       -5.8189e-02,  1.0340e-01,  2.0761e-03,  5.5460e-02, -1.1627e-01],\n",
       "                      [ 8.4641e-04, -4.0153e-02, -1.0358e-01, -8.5178e-02, -1.1979e-01,\n",
       "                        2.0535e-02,  3.6215e-02, -3.1722e-02, -4.3994e-02,  8.9102e-02,\n",
       "                       -8.6629e-02,  6.1482e-02, -6.0035e-02, -1.0456e-01,  3.6791e-02,\n",
       "                        6.5097e-02, -2.4275e-02,  6.4259e-02, -8.9452e-02,  1.0994e-01,\n",
       "                       -2.0055e-02,  1.1886e-01,  1.0879e-02,  5.0271e-02, -3.7557e-02,\n",
       "                       -6.4504e-02, -6.1472e-03,  1.2892e-01, -9.4988e-02, -1.2742e-01,\n",
       "                       -1.0707e-02, -5.1895e-02, -6.9885e-02,  5.4112e-02,  1.6989e-02,\n",
       "                       -9.9088e-02,  6.7404e-02,  5.4003e-02, -2.2080e-02, -7.3245e-02,\n",
       "                       -7.4726e-02,  5.8301e-02, -4.4286e-02,  1.1095e-01,  3.1430e-02,\n",
       "                        8.6312e-02,  6.2142e-02, -1.2383e-01, -1.1513e-01, -2.9595e-02,\n",
       "                       -9.8092e-02,  9.9725e-02,  1.0775e-01,  7.8106e-02,  1.2498e-01,\n",
       "                       -1.1844e-01,  1.1079e-01,  2.5868e-02, -3.9639e-02,  4.3672e-02],\n",
       "                      [ 8.1973e-02,  4.7528e-02,  7.8368e-02, -4.0877e-02,  8.7462e-02,\n",
       "                        4.7085e-02,  3.0902e-02, -7.7581e-02,  1.2689e-01, -8.0658e-02,\n",
       "                        8.8535e-02,  1.0617e-01, -5.0805e-02,  7.6526e-02, -7.8368e-02,\n",
       "                        2.1602e-02, -7.5334e-03,  5.0401e-02, -1.1617e-02, -7.5482e-02,\n",
       "                       -9.7883e-02, -6.3241e-02,  8.3685e-02,  5.6239e-02,  9.4236e-02,\n",
       "                        1.1014e-01, -4.3129e-02, -3.8697e-02, -1.0573e-01,  7.6392e-02,\n",
       "                       -1.2102e-01, -7.3066e-02, -5.7243e-02,  8.5485e-02,  7.5831e-02,\n",
       "                        1.2554e-01, -5.7177e-02, -3.5101e-02, -7.8403e-02, -6.7761e-02,\n",
       "                        1.0375e-01,  9.6467e-03,  9.3856e-02, -3.6978e-02, -1.1744e-01,\n",
       "                       -4.4999e-02, -4.3415e-02,  1.1724e-01,  1.9056e-02, -8.8075e-02,\n",
       "                       -3.9760e-02,  8.2343e-02,  2.1417e-02, -4.9229e-02,  1.4582e-02,\n",
       "                       -5.6201e-02, -7.3187e-02, -5.9902e-02,  1.2266e-02,  6.8223e-02],\n",
       "                      [ 8.4787e-02, -9.3954e-02,  1.2895e-01,  6.2922e-02,  8.7482e-02,\n",
       "                       -5.5176e-02,  5.5449e-03, -5.4490e-02, -8.3554e-02,  1.6590e-02,\n",
       "                       -7.1600e-02,  3.1087e-02,  6.1562e-02,  1.2629e-01,  2.0536e-02,\n",
       "                        8.6844e-02,  1.1073e-01, -9.8563e-02, -1.2067e-01,  3.1253e-02,\n",
       "                       -7.9884e-02,  2.7372e-02,  6.3076e-02,  8.4362e-02, -1.2100e-01,\n",
       "                       -1.2395e-01, -9.9920e-02, -6.1958e-02, -4.4180e-02, -2.3288e-02,\n",
       "                       -7.0213e-02,  7.9193e-02,  5.4740e-02, -5.8380e-02, -1.2271e-01,\n",
       "                       -1.0707e-01, -1.2230e-01, -1.5474e-02, -8.8792e-02,  8.1276e-02,\n",
       "                        6.4404e-02,  3.5603e-02, -1.2872e-01,  1.2662e-02, -4.7950e-02,\n",
       "                       -5.5050e-02,  5.4655e-02,  9.5103e-02, -6.2757e-02, -1.0094e-01,\n",
       "                        7.0529e-02, -2.1961e-02,  1.6983e-02, -5.0947e-02, -5.8206e-02,\n",
       "                       -2.9329e-03,  3.0099e-02, -6.0740e-02, -9.6698e-02,  7.1600e-02],\n",
       "                      [ 1.0330e-01, -3.9323e-02, -7.1140e-02, -7.5118e-02,  2.3123e-02,\n",
       "                        4.5902e-02,  1.2286e-01, -8.0835e-02, -1.1213e-01, -4.7471e-02,\n",
       "                        1.0300e-01,  2.6322e-02, -6.4011e-03, -1.1961e-02,  1.1082e-01,\n",
       "                        3.3107e-02,  1.1344e-01,  9.8948e-02,  3.1888e-02, -1.2094e-01,\n",
       "                        2.1419e-02,  6.8278e-02, -6.1701e-02, -1.0590e-02, -9.1785e-02,\n",
       "                        9.7119e-02, -1.2905e-01, -5.7221e-02, -1.1315e-01, -1.2340e-01,\n",
       "                        1.1138e-01,  8.6536e-02,  9.9087e-02,  1.0147e-01,  1.0813e-02,\n",
       "                       -8.1480e-02,  4.2077e-02, -1.1745e-01,  5.7138e-02, -1.0817e-01,\n",
       "                        1.1119e-01,  1.6514e-02,  2.3743e-02,  2.4952e-02,  9.3353e-02,\n",
       "                        4.2010e-02,  1.5479e-02, -1.2256e-01,  9.0681e-02, -1.0924e-01,\n",
       "                        9.4860e-03,  1.2685e-02,  2.2676e-02, -7.1708e-02, -2.1478e-03,\n",
       "                        6.1696e-02, -3.7268e-02, -5.6709e-02, -1.9172e-02, -1.2048e-01],\n",
       "                      [ 1.1185e-01, -4.9786e-02, -1.7844e-02, -6.0905e-02,  5.7437e-02,\n",
       "                       -6.2040e-02,  7.9854e-02,  4.6837e-02, -1.2019e-01,  7.3472e-03,\n",
       "                       -9.0534e-02, -9.8838e-02, -1.2207e-01, -7.7337e-02, -7.6140e-02,\n",
       "                        9.1751e-02, -6.9919e-02,  1.4648e-02,  2.8176e-02,  6.9220e-02,\n",
       "                        1.0548e-01, -6.0316e-02,  8.6173e-02,  1.0826e-01, -3.6598e-02,\n",
       "                        3.9275e-02,  1.0513e-01,  3.6941e-03, -6.3907e-02,  7.9964e-02,\n",
       "                       -1.1254e-01, -2.8440e-02, -7.9030e-02,  2.2358e-02, -4.4902e-02,\n",
       "                        9.0102e-02,  8.1205e-02, -8.0985e-02,  3.8784e-02,  9.5712e-02,\n",
       "                        4.0049e-02,  1.2377e-01,  7.5630e-02, -6.3255e-02, -4.4021e-02,\n",
       "                        1.2540e-01, -7.7398e-03, -3.4381e-02,  6.5855e-02,  2.6702e-02,\n",
       "                        1.7396e-02,  8.0864e-02,  1.1344e-01,  2.3117e-02, -9.6952e-02,\n",
       "                       -2.3224e-02,  1.1124e-02, -3.7736e-02,  4.3719e-02,  8.1876e-02],\n",
       "                      [-1.1308e-01,  1.0594e-01,  8.9030e-02, -4.8218e-02, -4.8935e-02,\n",
       "                        7.3160e-02, -2.0681e-02,  5.6680e-02,  4.6171e-02,  2.3037e-02,\n",
       "                        8.1720e-02,  1.4017e-02,  3.5870e-03, -9.0419e-02,  2.5832e-02,\n",
       "                       -1.5251e-02, -2.3855e-02, -1.2733e-01, -4.4297e-02, -7.8977e-03,\n",
       "                       -3.4912e-04, -3.0774e-03,  9.2072e-02,  1.7166e-02, -1.7908e-02,\n",
       "                       -2.7590e-02, -7.1339e-02,  1.1072e-01,  1.0741e-01,  6.9509e-02,\n",
       "                       -2.0203e-02, -1.1241e-01,  9.7818e-02,  2.8892e-02,  1.1643e-01,\n",
       "                       -4.3567e-02,  8.8681e-02,  8.5681e-02, -4.9232e-02,  4.8438e-02,\n",
       "                       -6.9400e-02,  1.1120e-01,  6.7399e-02,  7.4674e-02, -3.3979e-02,\n",
       "                       -6.5627e-02,  7.5507e-02,  7.3192e-02, -1.1376e-01,  1.2318e-01,\n",
       "                        5.7809e-02,  8.6488e-02, -8.0772e-02, -4.1599e-02, -1.4051e-02,\n",
       "                       -5.9438e-02,  9.1167e-02,  5.1093e-03,  1.1970e-01, -7.8430e-02],\n",
       "                      [ 8.3345e-02,  1.0510e-02, -1.0954e-01, -1.3784e-02, -8.5272e-02,\n",
       "                        1.1178e-01,  4.9779e-02,  1.0024e-01,  5.5271e-02, -1.0464e-02,\n",
       "                       -5.4471e-02,  6.4682e-02,  1.3676e-02,  7.5189e-02, -1.8558e-02,\n",
       "                        4.7814e-03,  4.3230e-02,  6.9444e-02,  9.6392e-02, -2.0520e-02,\n",
       "                        3.7178e-02,  9.6273e-02,  1.0260e-01,  9.7078e-02,  6.2732e-02,\n",
       "                       -1.2573e-01, -4.5721e-02,  1.2241e-01, -8.8533e-02, -8.4425e-02,\n",
       "                        5.4307e-03, -6.5347e-02, -9.5325e-02, -4.8284e-02,  9.0708e-02,\n",
       "                       -1.2303e-01,  6.1321e-02,  8.6454e-02,  3.2726e-02,  1.0306e-01,\n",
       "                       -1.2772e-01,  8.4430e-02, -8.6893e-02,  3.1639e-03,  1.1607e-01,\n",
       "                       -8.9686e-02,  1.2086e-02, -1.5313e-02,  7.1902e-02,  1.1415e-01,\n",
       "                        5.8182e-02, -1.2199e-01,  5.7413e-02, -5.6673e-02,  1.2596e-01,\n",
       "                       -4.5080e-02,  1.0305e-01, -1.1571e-01,  4.4839e-02,  6.1391e-02],\n",
       "                      [ 4.9971e-02,  6.7179e-03, -4.5670e-02, -9.1517e-02, -1.2573e-02,\n",
       "                        4.9423e-02,  8.2126e-02,  7.7280e-02, -8.7936e-02,  5.5135e-02,\n",
       "                       -9.3399e-04, -1.0215e-01, -2.6807e-02,  1.6393e-02, -2.1265e-03,\n",
       "                       -1.3123e-04,  1.2209e-01, -4.3346e-02,  9.8805e-02, -5.0266e-02,\n",
       "                        6.1953e-02,  2.1258e-02,  3.4571e-02,  6.9749e-02, -6.5307e-02,\n",
       "                        7.9163e-02,  1.2184e-01,  1.0844e-01, -7.2608e-02, -5.8305e-02,\n",
       "                       -6.9493e-04,  6.4721e-02,  7.5857e-02,  9.0434e-02,  1.1483e-01,\n",
       "                        1.0668e-01, -7.0548e-02, -9.4917e-02, -4.2848e-02, -3.9830e-02,\n",
       "                        1.1083e-03,  1.1181e-01,  2.5697e-02, -5.7402e-02,  2.6204e-02,\n",
       "                       -7.4172e-02, -6.2562e-02,  7.6482e-02,  9.1553e-02,  1.2667e-01,\n",
       "                       -4.6440e-02,  5.9143e-05, -7.7480e-02,  9.4761e-02,  2.3517e-02,\n",
       "                        9.0497e-02,  3.4772e-02,  1.0363e-01,  7.6784e-02, -8.9403e-02],\n",
       "                      [-1.0503e-02,  1.1453e-02,  9.7786e-03, -3.4336e-02, -8.8845e-02,\n",
       "                        1.2169e-01,  1.2432e-01,  9.4010e-02,  6.8020e-02,  1.0359e-01,\n",
       "                       -8.9620e-02,  1.1519e-01, -1.1971e-01,  9.1182e-02, -1.4239e-02,\n",
       "                       -8.5824e-02,  1.0937e-01,  9.5099e-02, -1.2452e-01,  1.9994e-02,\n",
       "                        1.0814e-01, -7.0919e-02, -2.3093e-02, -1.1188e-01,  4.1723e-03,\n",
       "                       -8.3282e-02, -9.7749e-02, -1.2771e-01, -3.2651e-02, -6.8469e-02,\n",
       "                        1.1035e-02, -5.6195e-02,  4.4006e-02, -5.1592e-02, -1.0234e-01,\n",
       "                        5.8312e-02, -5.2512e-02, -8.5109e-02, -9.9932e-02,  1.0379e-01,\n",
       "                        1.1231e-01, -1.2650e-01, -1.0089e-01,  2.0589e-02, -8.1956e-02,\n",
       "                       -7.2190e-02,  1.0370e-01, -1.3918e-02,  1.3430e-03,  2.7227e-02,\n",
       "                       -1.7083e-03, -1.0595e-01, -7.5742e-02, -7.6243e-02, -5.4576e-02,\n",
       "                       -6.8718e-02,  7.1973e-02,  1.1205e-01,  8.3342e-02,  5.6568e-02],\n",
       "                      [ 6.4962e-02, -1.8750e-02,  6.6162e-02, -7.1537e-02,  9.3850e-02,\n",
       "                       -2.4684e-02,  4.6312e-02, -3.2285e-03,  3.0536e-02,  4.4447e-02,\n",
       "                        5.3812e-02,  5.6688e-02, -1.2365e-01, -1.2030e-01,  7.1065e-03,\n",
       "                       -7.0865e-02,  4.5364e-02, -5.2725e-03,  2.5659e-02,  8.3937e-02,\n",
       "                       -1.0343e-01,  4.7271e-02, -3.5951e-02,  6.8868e-02,  1.1043e-01,\n",
       "                        4.7178e-02,  6.5466e-02,  4.0766e-02, -9.5448e-02,  8.7713e-02,\n",
       "                        2.3630e-02, -6.7055e-02, -3.9916e-02,  6.1963e-02, -5.5529e-02,\n",
       "                       -1.1764e-01, -1.1287e-02,  1.1288e-01,  1.2873e-01,  4.1267e-02,\n",
       "                       -5.3451e-02, -1.7234e-02,  4.7636e-03,  5.3602e-03, -8.5796e-02,\n",
       "                        9.0235e-02,  1.0601e-01,  2.4341e-02, -1.0521e-02, -2.9018e-02,\n",
       "                        1.0143e-01,  1.1861e-01,  1.0456e-01, -9.2493e-02, -3.5135e-02,\n",
       "                        3.5238e-02,  1.0020e-01, -1.3404e-02, -9.7429e-03,  3.1614e-02]])),\n",
       "             ('linear_relu_stack.0.bias',\n",
       "              tensor([ 0.1147, -0.0678, -0.0975,  0.0285, -0.1285,  0.1092, -0.1025, -0.0352,\n",
       "                      -0.0134,  0.1211,  0.0558, -0.0229, -0.0762,  0.0297, -0.0418,  0.0266])),\n",
       "             ('linear_relu_stack.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('linear_relu_stack.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('linear_relu_stack.3.weight',\n",
       "              tensor([[-0.1646,  0.0735, -0.2438,  0.1246,  0.2172,  0.2291, -0.0013, -0.2308,\n",
       "                       -0.2031,  0.0727,  0.0492, -0.2033,  0.1908,  0.1843, -0.1462,  0.0399]])),\n",
       "             ('linear_relu_stack.3.bias', tensor([-0.2453]))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4984ef40-91ea-4346-9106-68a9ee261d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8bf5b63-56a4-41df-b225-f57d2173d217",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('n_averaged', tensor(49)), ('module.linear_relu_stack.0.weight', tensor([[ 9.4920e-03,  6.7218e-03,  5.2324e-03,  ..., -3.6216e-02,\n",
       "          9.1493e-03, -2.2433e-02],\n",
       "        [-2.7310e-03,  1.0898e-02,  7.3623e-03,  ...,  4.8998e-02,\n",
       "          3.4605e-02,  6.2091e-02],\n",
       "        [ 2.4966e-03, -2.6011e-03,  1.2573e-02,  ..., -6.4834e-02,\n",
       "         -1.1924e-02, -3.8306e-02],\n",
       "        ...,\n",
       "        [ 8.0831e-03, -7.2475e-03, -3.0723e-03,  ...,  1.9825e-03,\n",
       "         -1.2995e-02,  1.4359e-02],\n",
       "        [ 7.9673e-03, -3.2430e-05,  1.1558e-02,  ..., -6.4105e-02,\n",
       "         -2.6581e-02, -3.4876e-02],\n",
       "        [-5.1869e-03, -2.2085e-02, -1.7314e-02,  ...,  1.3046e-02,\n",
       "         -1.5962e-04, -2.5373e-02]], dtype=torch.float64)), ('module.linear_relu_stack.0.bias', tensor([ 0.0042,  0.0054,  0.0016, -0.0095,  0.0019, -0.0018, -0.0069,  0.0025,\n",
       "         0.0030,  0.0062,  0.0041,  0.0057,  0.0048, -0.0014,  0.0071, -0.0036],\n",
       "       dtype=torch.float64)), ('module.linear_relu_stack.1.weight', tensor([0.8458, 0.8080, 0.9615, 0.7760, 1.0476, 0.8375, 1.2638, 0.8060, 1.2378,\n",
       "        0.8285, 0.7922, 0.8605, 0.8047, 0.8357, 1.0382, 0.7468],\n",
       "       dtype=torch.float64)), ('module.linear_relu_stack.1.bias', tensor([ 0.0967, -0.0313,  0.1457, -0.0229,  0.1783,  0.2286,  0.1026, -0.0041,\n",
       "         0.1980, -0.0314,  0.0717, -0.0062, -0.0198, -0.0344,  0.1885,  0.0291],\n",
       "       dtype=torch.float64)), ('module.linear_relu_stack.3.weight', tensor([[ 0.2055, -0.0232,  0.2655,  0.0151,  0.2066,  0.0830, -0.3771, -0.1515,\n",
       "         -0.5102, -0.0647,  0.1506, -0.1380, -0.0806, -0.0392,  0.3689,  0.0408]],\n",
       "       dtype=torch.float64)), ('module.linear_relu_stack.3.bias', tensor([-0.1224], dtype=torch.float64))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9df13397-eec1-47cc-8fb9-a40bb2575083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0686c38b-0349-4707-9596-0d977bb9c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lstrip'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"module.lstrip\".replace(\"module.\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58517df1-89d0-4ce6-9717-98629b30b8d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NeuralNetwork:\n\tUnexpected key(s) in state_dict: \"n_averaged\". \n\tsize mismatch for linear_relu_stack.0.weight: copying a param with shape torch.Size([16, 3780]) from checkpoint, the shape in current model is torch.Size([16, 60]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22418/272985957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/ssd/scratch/kellner/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NeuralNetwork:\n\tUnexpected key(s) in state_dict: \"n_averaged\". \n\tsize mismatch for linear_relu_stack.0.weight: copying a param with shape torch.Size([16, 3780]) from checkpoint, the shape in current model is torch.Size([16, 60])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b81043c7-4b71-4613-a865-3db2ce4e780b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd/scratch/kellner/COSMO_project/uncertainty/multi_NN_v2'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7a6ba-6759-48e4-a638-c4a99e9a76f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
