{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6701813-2781-4abe-9d99-5c36479988a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn import GaussianNLLLoss\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832343ee-f9e1-46c6-929e-7b98f5d5d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_NN = {\"v1\":None,\"v2\":None}\n",
    "\n",
    "#NN:\n",
    "TRUTH_TRAIN_IDENTIFIER = \"./multi_NN_{}/specie_{}_true_train_complete.npy\"\n",
    "TRUTH_TEST_IDENTIFIER = \"./multi_NN_{}/specie_{}_true_test.npy\"\n",
    "FULL_TRAIN_IDENTIFIER = \"./multi_NN_{}/specie_{}_model_no_{}_predictions_train_complete.npy\"\n",
    "FULL_TEST_IDENTIFIER = \"./multi_NN_{}/specie_{}_model_no_{}_predictions_test.npy\"\n",
    "ONE_HOT_IDENTIFIER = \"./multi_NN_{}/membership_specie_{}_model_{}_one_hot_train.npy\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TRUTH_TRAIN_IDENTIFIER = \"./multi_NN_{}/specie_{}_true_train_complete.npy\"\n",
    "TRUTH_TEST_IDENTIFIER = \"./multi_NN_{}/specie_{}_true_test.npy\"\n",
    "FULL_TRAIN_IDENTIFIER = \"./multi_kernel_{}/specie_{}_model_no_{}_full_test_pred.npy\"\n",
    "FULL_TEST_IDENTIFIER = \"./multi_kernel_{}/specie_{}_model_no_{}_test_pred.npy\"\n",
    "ONE_HOT_IDENTIFIER = \"./multi_kernel_{}/specie_{}_model_no_{}_one_hot.npy\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for degree in [\"v1\",\"v2\"]:\n",
    "    train_true = {}\n",
    "    test_true = {}\n",
    "    pred_train = {}\n",
    "    pred_test = {}\n",
    "    one_hot = {}\n",
    "    means_train = {}\n",
    "    means_test = {}\n",
    "    residuals_train = {}\n",
    "    residuals_test = {}\n",
    "   \n",
    "    \n",
    "    for specie in [1,6,7,8]:\n",
    "        train_true[specie] = np.load(TRUTH_TRAIN_IDENTIFIER.format(degree,specie))\n",
    "        test_true[specie] = np.load(TRUTH_TEST_IDENTIFIER.format(degree,specie))\n",
    "        pred_train[specie] = []\n",
    "        pred_test[specie] = []\n",
    "        one_hot[specie] = []\n",
    "        for model in range(16):\n",
    "            pred_train[specie].append(np.load(FULL_TRAIN_IDENTIFIER.format(degree,specie,model)))\n",
    "            pred_test[specie].append(np.load(FULL_TEST_IDENTIFIER.format(degree,specie,model)))\n",
    "            one_hot[specie].append(np.load(ONE_HOT_IDENTIFIER.format(degree,specie,model)))\n",
    "        \n",
    "       \n",
    "        pred_train[specie] = np.vstack(pred_train[specie]).T\n",
    "        pred_test[specie] = np.vstack(pred_test[specie]).T\n",
    "        one_hot[specie] = np.vstack(one_hot[specie]).T\n",
    "        means_train[specie] = np.mean(pred_train[specie],axis=1)\n",
    "        means_test[specie] = np.mean(pred_test[specie],axis=1)\n",
    "        #residuals_train[specie] = np.abs(train_true[specie]- means[specie])\n",
    "    \n",
    "    results_NN[degree] = {\"train_true\":train_true,\"test_true\":test_true,\"means_train\":means_train,\"means_test\":means_test,\"pred_train\":pred_train,\"pred_test\":pred_test,\"one_hot\":one_hot}\n",
    "    \n",
    "    \n",
    "    \n",
    "ridge_results = {\"v1\":None,\"v2\":None}\n",
    "ridge_results[\"v1\"] = {\"pred_train\":{},\"pred_test\":{},\"one_hot\":{},\"means_train\":{},\"means_test\":{},\"test_true\":{k:results_NN[\"v1\"][\"test_true\"][k] for k in [1,6,7,8]},\"train_true\":{k:results_NN[\"v1\"][\"train_true\"][k] for k in [1,6,7,8]}}\n",
    "ridge_results[\"v2\"] = {\"pred_train\":{},\"pred_test\":{},\"one_hot\":{},\"means_train\":{},\"means_test\":{},\"test_true\":{k:results_NN[\"v2\"][\"test_true\"][k] for k in [1,6,7,8]},\"train_true\":{k:results_NN[\"v2\"][\"train_true\"][k] for k in [1,6,7,8]}}\n",
    "\n",
    "\n",
    "for v in [1]:\n",
    "    for species in [1,6,7,8]:\n",
    "        pred_test = []\n",
    "        pred_train = []\n",
    "        one_hot_train = []\n",
    "        \n",
    "        for i in range(16):\n",
    "                pred_test.append(np.load(\"./multi_ridge_v{}/specie_{}_model_no_{}_test_pred.npy\".format(v,species,i)))\n",
    "                pred_train.append(np.load(\"./multi_ridge_v{}/specie_{}_model_no_{}_full_test_pred.npy\".format(v,species,i)))\n",
    "                one_hot_train.append(np.load(\"./multi_ridge_v{}/specie_{}_model_no_{}_one_hot.npy\".format(v,species,i)))\n",
    "        \n",
    "        pred_test = np.vstack(pred_test).T\n",
    "        pred_train = np.vstack(pred_train).T\n",
    "        one_hot_train = np.vstack(one_hot_train).T\n",
    "    \n",
    "        ridge_results[\"v1\"][\"pred_train\"][species] = pred_train    \n",
    "        ridge_results[\"v1\"][\"pred_test\"][species] = pred_test\n",
    "        ridge_results[\"v1\"][\"one_hot\"][species] = one_hot_train\n",
    "        ridge_results[\"v1\"][\"means_train\"][species] = np.mean(pred_train,axis=1)\n",
    "        ridge_results[\"v1\"][\"means_test\"][species] = np.mean(pred_test,axis=1)               \n",
    "        \n",
    "for species, a_num in zip([\"1H\", \"13C\", \"15N\", \"17O\"],[1,6,7,8]):\n",
    "    pred_test = np.load(\"./multi_ridge_v2/{}_test_commitee_prediction.npy\".format(species))\n",
    "    pred_train = np.load(\"./multi_ridge_v2/{}_commitee_prediction.npy\".format(species))\n",
    "    one_hot_train = np.load(\"./multi_ridge_v2/{}_train_binary_1_hot_N_sample_M_models.npy\".format(species))\n",
    "    \n",
    "                       \n",
    "    ridge_results[\"v2\"][\"pred_train\"][a_num] = pred_train    \n",
    "    ridge_results[\"v2\"][\"pred_test\"][a_num] = pred_test\n",
    "    ridge_results[\"v2\"][\"one_hot\"][a_num]= one_hot_train\n",
    "    ridge_results[\"v2\"][\"means_train\"][a_num] = np.mean(pred_train,axis=1)\n",
    "    ridge_results[\"v2\"][\"means_test\"][a_num] = np.mean(pred_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4c3f18-5837-43b1-8d15-4ba821509a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e4de12d-df6c-4ad0-bccb-8f01cba2f674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.40711454]\n",
      "NLL v1 no rescale: 933.20\n",
      "NLL v1 alpha rescale: 1.64\n",
      "NLL v1 a,b,g rescale: 1.52\n",
      "NLL v1 worst: 1.61\n",
      "NLL v1 best: 0.91\n",
      "NLL v2 no rescale: 13.31\n",
      "NLL v2 alpha rescale: 0.69\n",
      "NLL v2 a,b,g, rescale: 0.65\n",
      "NLL v2 worst: 0.68\n",
      "NLL v2 best: -0.04\n",
      "species: 1, v1 before rescale : 0.00\n",
      "species: 1, v1 rescale a : 0.00\n",
      "species: 1, v1 rescale a,g : 2.52\n",
      "species: 1, v1 rescale a,b,g : 2.41\n",
      "species: 1, v2 before rescale : 0.00\n",
      "species: 1, v2 rescale a : 0.00\n",
      "species: 1, v2 rescale a,g : 4.68\n",
      "species: 1, v2 rescale a,b,g : 4.84\n",
      "[5.02753776]\n",
      "0.4777233772507114\n",
      "[4.41584666]\n",
      "NLL v1 no rescale: 454.34\n",
      "NLL v1 alpha rescale: 3.86\n",
      "NLL v1 a,b,g rescale: 3.72\n",
      "NLL v1 worst: 3.65\n",
      "NLL v1 best: 2.84\n",
      "NLL v2 no rescale: 9.66\n",
      "NLL v2 alpha rescale: 2.85\n",
      "NLL v2 a,b,g, rescale: 2.82\n",
      "NLL v2 worst: 2.91\n",
      "NLL v2 best: 2.09\n",
      "species: 6, v1 before rescale : 0.00\n",
      "species: 6, v1 rescale a : 11.24\n",
      "species: 6, v1 rescale a,g : 9.20\n",
      "species: 6, v1 rescale a,b,g : 9.20\n",
      "species: 6, v2 before rescale : 0.00\n",
      "species: 6, v2 rescale a : 7.79\n",
      "species: 6, v2 rescale a,g : 10.52\n",
      "species: 6, v2 rescale a,b,g : 10.44\n",
      "[4.31009696]\n",
      "NLL v1 no rescale: 150.48\n",
      "NLL v1 alpha rescale: 5.07\n",
      "NLL v1 a,b,g rescale: 4.99\n",
      "NLL v1 worst: 5.01\n",
      "NLL v1 best: 4.14\n",
      "NLL v2 no rescale: 7.78\n",
      "NLL v2 alpha rescale: 3.80\n",
      "NLL v2 a,b,g, rescale: 3.80\n",
      "NLL v2 worst: 4.06\n",
      "NLL v2 best: 3.08\n",
      "species: 7, v1 before rescale : 0.00\n",
      "species: 7, v1 rescale a : 14.45\n",
      "species: 7, v1 rescale a,g : 13.87\n",
      "species: 7, v1 rescale a,b,g : 13.90\n",
      "species: 7, v2 before rescale : 0.00\n",
      "species: 7, v2 rescale a : 26.28\n",
      "species: 7, v2 rescale a,g : 26.89\n",
      "species: 7, v2 rescale a,b,g : 26.22\n",
      "[3.91948738]\n",
      "NLL v1 no rescale: 246.00\n",
      "NLL v1 alpha rescale: 5.34\n",
      "NLL v1 a,b,g rescale: 5.26\n",
      "NLL v1 worst: 5.38\n",
      "NLL v1 best: 4.62\n",
      "NLL v2 no rescale: 8.28\n",
      "NLL v2 alpha rescale: 4.22\n",
      "NLL v2 a,b,g, rescale: 4.21\n",
      "NLL v2 worst: 4.28\n",
      "NLL v2 best: 3.44\n",
      "species: 8, v1 before rescale : 0.00\n",
      "species: 8, v1 rescale a : 10.30\n",
      "species: 8, v1 rescale a,g : 9.27\n",
      "species: 8, v1 rescale a,b,g : 9.19\n",
      "species: 8, v2 before rescale : 0.00\n",
      "species: 8, v2 rescale a : 7.55\n",
      "species: 8, v2 rescale a,g : 8.23\n",
      "species: 8, v2 rescale a,b,g : 8.53\n"
     ]
    }
   ],
   "source": [
    "result_dict = ridge_results\n",
    "\n",
    "\"\"\"\n",
    "def minimize(*args,**kwargs):\n",
    "    mode = kwargs.pop(\"mode\")\n",
    "    if mode == \"local\":\n",
    "        return scipy.optimize.minimize(*args,**kwargs)\n",
    "    elif mode == \"global\":\n",
    "        for_local_minimizer = kwargs.pop(\"args\")\n",
    "        return scipy.optimize.basinhopping(*args,**kwargs,niter=100,T=0.5,minimizer_kwargs={\"args\":for_local_minimizer})\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\"\"\"\n",
    "\n",
    "def neglog_likelihood(ystd,ymeans,ytrue):\n",
    "    #**2\n",
    "    #**2\n",
    "    ll = np.mean(-0.5*np.log(2*np.pi*(ystd**2)) - (ymeans-ytrue)**2/(2*(ystd**2)))\n",
    "    return -ll\n",
    "\n",
    "def neglog_likelihood_rescale(x,ystd,ymeans,ytrue,rescale,nll=neglog_likelihood):\n",
    "    ystd = rescale(ystd,*x)\n",
    "    return nll(ystd,ymeans,ytrue)\n",
    "\n",
    "def rescale_a(ystd,alpha):\n",
    "    return np.sqrt(alpha**2 * ystd**2)\n",
    "\n",
    "def rescale_a_g(ystd,alpha,gamma):\n",
    "    return np.sqrt(alpha**2 * ystd**(gamma+2))    \n",
    "\n",
    "def rescale_a_b_g(ystd,alpha,beta,gamma):\n",
    "    return np.sqrt(alpha**2 * ystd**(gamma+2) + beta**2)   \n",
    "\n",
    "def neglog_likelihood_torch(ystd,ymeans,ytrue):\n",
    "    loss = GaussianNLLLoss(full=True)\n",
    "    ystd = torch.Tensor(ystd.reshape(-1,1))\n",
    "    ymeans = torch.Tensor(ymeans.reshape(-1,1))\n",
    "    ytrue = torch.Tensor(ytrue.reshape(-1,1))\n",
    "    return loss(ymeans, ytrue, ystd**2)\n",
    "\n",
    "def small_correction(alpha,M):\n",
    "    return np.sqrt(-1/M + (M-3)/(M-1) * alpha**2)\n",
    "\n",
    "def combined_pred(pred_1,pred_2,rescale_1,rescale_2,rescale_1_params,rescale_2_params):\n",
    "    \"\"\"passing a (N_samples,N_models) array of predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_1 = pred_1.mean(axis=1)\n",
    "    mean_2 = pred_2.mean(axis=1)\n",
    "    \n",
    "    std_1 = pred_1.std(axis=1,ddof=1)\n",
    "    std_2 = pred_2.std(axis=1,ddof=1)\n",
    "    \n",
    "    std_1 = rescale_1(std_1,*rescale_1_params)\n",
    "    std_2 = rescale_2(std_2,*rescale_2_params)\n",
    "    \n",
    "    final_pred = (1/std_1**2 + 1/std_2**2)**-1 * (1/std_1**2 * mean_1 + 1/std_2**2 * mean_2)\n",
    "    \n",
    "    return final_pred\n",
    "\n",
    "def dimensionless_coeff(LLworst,LLbest,LLactual):\n",
    "        return max((LLworst-LLactual),0)/(LLworst-LLbest)*100\n",
    "    \n",
    "params_NN = {}\n",
    "\n",
    "for a_specie in [1,6,7,8]:\n",
    "    \n",
    "    int_param = {\"alpha_v1\":None,\"alpha_v2\":None,\"beta_v1\":None,\"beta_v2\":None,\"gamma_v1\":None,\"gamma_v2\":None}\n",
    "    \n",
    "    pred_v1 = np.copy(result_dict[\"v1\"][\"pred_train\"][a_specie])\n",
    "    pred_v1_test = np.copy(result_dict[\"v1\"][\"pred_test\"][a_specie])\n",
    "    mean_v1 = np.copy(result_dict[\"v1\"][\"means_train\"][a_specie])\n",
    "    mean_v1_test = np.copy(result_dict[\"v1\"][\"means_test\"][a_specie])\n",
    "    \n",
    "    pred_v2 = np.copy(result_dict[\"v2\"][\"pred_train\"][a_specie])\n",
    "    pred_v2_test = np.copy(result_dict[\"v2\"][\"pred_test\"][a_specie])\n",
    "    mean_v2 = np.copy(result_dict[\"v2\"][\"means_train\"][a_specie])\n",
    "    mean_v2_test = np.copy(result_dict[\"v2\"][\"means_test\"][a_specie])\n",
    "    \n",
    "    truth = np.copy(result_dict[\"v1\"][\"train_true\"][a_specie])\n",
    "    truth_test = np.copy(result_dict[\"v1\"][\"test_true\"][a_specie])\n",
    "\n",
    "\n",
    "    one_hot_v1 = np.copy(result_dict[\"v1\"][\"one_hot\"][a_specie])\n",
    "    one_hot_v2 = np.copy(result_dict[\"v2\"][\"one_hot\"][a_specie])\n",
    "    \n",
    "    #def loss(ymeans,ytrue,ystd):\n",
    "    \n",
    "    smaller5_v1 = np.sum(one_hot_v1,axis=1) < 11\n",
    "    smaller5_v2 = np.sum(one_hot_v2,axis=1) < 11\n",
    "    masked_commitee_pred_v1 = np.ma.masked_array(data=pred_v1,mask=one_hot_v1)\n",
    "    masked_commitee_pred_v2 = np.ma.masked_array(data=pred_v2,mask=one_hot_v2)\n",
    "\n",
    "    ystd_data_v1 = masked_commitee_pred_v1[smaller5_v1].std(ddof=1,axis=1)\n",
    "    ymeans_data_v1 = masked_commitee_pred_v1[smaller5_v1].mean(axis=1)\n",
    "    ytrue_data_v1 = np.copy(truth[smaller5_v1])\n",
    "\n",
    "    ystd_data_v2 = masked_commitee_pred_v2[smaller5_v2].std(ddof=1,axis=1)\n",
    "    ymeans_data_v2 = masked_commitee_pred_v2[smaller5_v2].mean(axis=1)\n",
    "    ytrue_data_v2 = np.copy(truth[smaller5_v2])\n",
    "\n",
    "    \n",
    "    #get NLLs and params\n",
    "    \n",
    "    min_res_alpha_only_v1 = minimize(neglog_likelihood_rescale,args=(ystd_data_v1,ymeans_data_v1,ytrue_data_v1,rescale_a),x0=np.array([1.]))\n",
    "    alpha_only_v1 = min_res_alpha_only_v1[\"x\"]\n",
    "    NLL_alpha_only_v1 = min_res_alpha_only_v1[\"fun\"]\n",
    "    \n",
    "    min_res_nonlin_v1 = minimize(neglog_likelihood_rescale,args=(ystd_data_v1,ymeans_data_v1,ytrue_data_v1,rescale_a_g),x0=np.array([1.,1.]))\n",
    "    alpha_nonlin_v1, gamma_nonlin_v1 = min_res_nonlin_v1[\"x\"]\n",
    "    NLL_nonlin_v1 = min_res_nonlin_v1[\"fun\"]\n",
    "    \n",
    "    min_res_full_v1 = minimize(neglog_likelihood_rescale,args=(ystd_data_v1,ymeans_data_v1,ytrue_data_v1,rescale_a_b_g),x0=np.array([1.,1.,1.]))\n",
    "    alpha_v1, beta_v1, gamma_v1 = min_res_full_v1[\"x\"]\n",
    "    NLL_full_v1 = min_res_full_v1[\"fun\"]\n",
    "    \n",
    "    min_res_alpha_only_v2 = minimize(neglog_likelihood_rescale,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2,rescale_a),x0=np.array([1.]))\n",
    "    alpha_only_v2 = min_res_alpha_only_v2[\"x\"]\n",
    "    print(alpha_only_v2)\n",
    "    NLL_alpha_only_v2 = min_res_alpha_only_v2[\"fun\"]\n",
    "    \n",
    "    min_res_nonlin_v2 = minimize(neglog_likelihood_rescale,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2,rescale_a_g),x0=np.array([1.,1.]))\n",
    "    alpha_nonlin_v2, gamma_nonlin_v2 = min_res_nonlin_v2[\"x\"]\n",
    "    NLL_nonlin_v2 = min_res_nonlin_v2[\"fun\"]\n",
    "    \n",
    "    min_res_full_v2 = minimize(neglog_likelihood_rescale,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2,rescale_a_b_g),x0=np.array([1.,1.,1.]))\n",
    "    alpha_v2, beta_v2, gamma_v2 = min_res_full_v2[\"x\"]\n",
    "    NLL_full_v2 = min_res_full_v2[\"fun\"]\n",
    "    \n",
    "    neglog_likelihood_no_rescale_v1 = neglog_likelihood(pred_v1_test.std(axis=1,ddof=1),mean_v1_test,truth_test)\n",
    "    neglog_likelihood_no_rescale_v2 = neglog_likelihood(pred_v2_test.std(axis=1,ddof=1),mean_v2_test,truth_test)\n",
    "    #test set RMSEs\n",
    "    \n",
    "    RMSE_v1 = mean_squared_error(truth_test,mean_v1_test,squared=False)\n",
    "    RMSE_v2 = mean_squared_error(truth_test,mean_v2_test,squared=False)\n",
    "    \n",
    "    errors_v1 = np.abs(truth_test-mean_v1_test)\n",
    "    errors_v2 = np.abs(truth_test-mean_v2_test)\n",
    "    \n",
    "    NLL_test_v1_a = neglog_likelihood_rescale([small_correction(alpha_only_v1,16)],pred_v1_test.std(axis=1,ddof=1),mean_v1_test,truth_test,rescale_a)\n",
    "    NLL_test_v1_a_g = neglog_likelihood_rescale([alpha_nonlin_v1, gamma_nonlin_v1],pred_v1_test.std(axis=1,ddof=1),mean_v1_test,truth_test,rescale_a_g)\n",
    "    NLL_test_v1_a_b_g = neglog_likelihood_rescale([alpha_v1, beta_v1, gamma_v1],pred_v1_test.std(axis=1,ddof=1),mean_v1_test,truth_test,rescale_a_b_g)\n",
    "    NLL_test_v2_a = neglog_likelihood_rescale([small_correction(alpha_only_v2,16)],pred_v2_test.std(axis=1,ddof=1),mean_v2_test,truth_test,rescale_a)\n",
    "    NLL_test_v2_a_g = neglog_likelihood_rescale([alpha_nonlin_v2, gamma_nonlin_v2],pred_v2_test.std(axis=1,ddof=1),mean_v2_test,truth_test,rescale_a_g)\n",
    "    NLL_test_v2_a_b_g = neglog_likelihood_rescale([alpha_v2, beta_v2, gamma_v2],pred_v2_test.std(axis=1,ddof=1),mean_v2_test,truth_test,rescale_a_b_g)\n",
    "    \n",
    "    NLL_worst_v1 = neglog_likelihood(RMSE_v1*np.ones(mean_v1_test.shape),mean_v1_test,truth_test)\n",
    "    NLL_best_v1 = neglog_likelihood(errors_v1,mean_v1_test,truth_test)\n",
    "     \n",
    "    NLL_worst_v2 = neglog_likelihood(RMSE_v2*np.ones(mean_v2_test.shape),mean_v2_test,truth_test)\n",
    "    NLL_best_v2 = neglog_likelihood(errors_v2,mean_v2_test,truth_test)\n",
    "    \n",
    "    print(\"NLL v1 no rescale: {:.2f}\".format(neglog_likelihood_no_rescale_v1))\n",
    "    print(\"NLL v1 alpha rescale: {:.2f}\".format(NLL_alpha_only_v1))\n",
    "    print(\"NLL v1 a,b,g rescale: {:.2f}\".format(NLL_full_v1))\n",
    "    print(\"NLL v1 worst: {:.2f}\".format(NLL_worst_v1))\n",
    "    print(\"NLL v1 best: {:.2f}\".format(NLL_best_v1))\n",
    "    \n",
    "    print(\"NLL v2 no rescale: {:.2f}\".format(neglog_likelihood_no_rescale_v2))\n",
    "    print(\"NLL v2 alpha rescale: {:.2f}\".format(NLL_test_v2_a))\n",
    "    print(\"NLL v2 a,b,g, rescale: {:.2f}\".format(NLL_test_v2_a_b_g))\n",
    "    print(\"NLL v2 worst: {:.2f}\".format(NLL_worst_v2))\n",
    "    print(\"NLL v2 best: {:.2f}\".format(NLL_best_v2))\n",
    "\n",
    "    \n",
    "    print(\"species: {}, v1 before rescale : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v1,NLL_best_v1,neglog_likelihood_no_rescale_v1)))\n",
    "    print(\"species: {}, v1 rescale a : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v1,NLL_best_v1,NLL_test_v1_a)))\n",
    "    print(\"species: {}, v1 rescale a,g : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v1,NLL_best_v1,NLL_test_v1_a_g)))\n",
    "    print(\"species: {}, v1 rescale a,b,g : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v1,NLL_best_v1,NLL_test_v1_a_b_g)))\n",
    "    \n",
    "    print(\"species: {}, v2 before rescale : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v2,NLL_best_v2,neglog_likelihood_no_rescale_v2)))\n",
    "    print(\"species: {}, v2 rescale a : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v2,NLL_best_v2,NLL_test_v2_a)))\n",
    "    print(\"species: {}, v2 rescale a,g : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v2,NLL_best_v2,NLL_test_v2_a_g)))\n",
    "    print(\"species: {}, v2 rescale a,b,g : {:.2f}\".format(a_specie,dimensionless_coeff(NLL_worst_v2,NLL_best_v2,NLL_test_v2_a_b_g)))\n",
    "    \n",
    "    \n",
    "    int_param[\"alpha_v1\"] = alpha_v1\n",
    "    int_param[\"alpha_v2\"] = alpha_v2\n",
    "    int_param[\"beta_v1\"] = beta_v1\n",
    "    int_param[\"beta_v2\"] = beta_v2\n",
    "    int_param[\"gamma_v1\"] = gamma_v1\n",
    "    int_param[\"gamma_v2\"] = gamma_v2\n",
    "    \n",
    "    params_NN[a_specie] = int_param\n",
    "    \n",
    "    #------------lazy testing------------\n",
    "    \n",
    "    if testing is True:\n",
    "        \n",
    "        #print(\"Testing\")\n",
    "        \n",
    "        for NLL in [NLL_alpha_only_v1,NLL_nonlin_v1,NLL_full_v1]:\n",
    "            assert dimensionless_coeff(NLL_worst_v1,NLL_best_v1,NLL) <= 100\n",
    "            assert dimensionless_coeff(NLL_worst_v1,NLL_best_v1,NLL) >= 0\n",
    "            assert dimensionless_coeff(NLL_worst_v1,NLL_best_v1,NLL_best_v1) == 100\n",
    "        \n",
    "        for NLL in [NLL_alpha_only_v2,NLL_nonlin_v2,NLL_full_v2]:\n",
    "            assert dimensionless_coeff(NLL_worst_v2,NLL_best_v2,NLL) <= 100\n",
    "            assert dimensionless_coeff(NLL_worst_v2,NLL_best_v2,NLL) >= 0\n",
    "            assert dimensionless_coeff(NLL_worst_v2,NLL_best_v2,NLL_best_v2) == 100\n",
    "        \n",
    "        assert NLL_worst_v1 != NLL_worst_v2\n",
    "        assert NLL_best_v1 != NLL_best_v2\n",
    "        assert NLL_best_v1 < NLL_worst_v1\n",
    "        assert NLL_best_v2 < NLL_worst_v2\n",
    "        assert NLL_best_v1 < NLL_alpha_only_v1\n",
    "        assert NLL_best_v2 < NLL_alpha_only_v2\n",
    "        assert NLL_best_v1 < NLL_full_v1\n",
    "        assert NLL_best_v2 < NLL_full_v2\n",
    "        assert NLL_best_v1 < NLL_nonlin_v1\n",
    "        assert NLL_best_v2 < NLL_nonlin_v2\n",
    "        \n",
    "        assert alpha_nonlin_v1 != alpha_nonlin_v2\n",
    "        assert gamma_nonlin_v1 != gamma_nonlin_v2\n",
    "        assert alpha_only_v1 != alpha_only_v2\n",
    "        assert alpha_v1 != alpha_v2\n",
    "        assert beta_v1 != beta_v2\n",
    "        assert gamma_v1 != gamma_v2\n",
    "        \n",
    "        assert NLL_alpha_only_v1 != NLL_alpha_only_v2\n",
    "        assert NLL_full_v1 != NLL_full_v2\n",
    "        assert NLL_nonlin_v1 != NLL_nonlin_v2\n",
    "        \n",
    "        assert np.allclose(neglog_likelihood_rescale(alpha_only_v1,ystd_data_v1,ymeans_data_v1,ytrue_data_v1,rescale_a),NLL_alpha_only_v1)\n",
    "        assert np.allclose(neglog_likelihood_rescale([alpha_nonlin_v1, gamma_nonlin_v1],ystd_data_v1,ymeans_data_v1,ytrue_data_v1,rescale_a_g),NLL_alpha_only_v1) is False\n",
    "        assert np.allclose(neglog_likelihood_rescale([alpha_nonlin_v1, gamma_nonlin_v1],ystd_data_v1,ymeans_data_v1,ytrue_data_v1,rescale_a_g),NLL_nonlin_v1)\n",
    "        \n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a,rescale_a,[alpha_only_v1],[alpha_only_v1])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_g,rescale_a_g,[alpha_nonlin_v1,gamma_nonlin_v1],[alpha_only_v1,gamma_nonlin_v1])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_b_g,rescale_a_b_g,[alpha_v1,beta_v1,gamma_v1],[alpha_v1,beta_v1,gamma_v1])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        \n",
    "        \n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a,rescale_a,[alpha_only_v1],[alpha_only_v1])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a,rescale_a,[alpha_only_v1],[1.])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a,rescale_a_b_g,[alpha_only_v1],[1.,1.,1.])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_b_g,rescale_a_b_g,[1.,1.,1.],[1.,1.,1.])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_b_g,rescale_a_b_g,[1.,0.1,1.],[0.1,1.,0.1])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_b_g,rescale_a_b_g,[1.,0.1,1.],[0.1,1.,0.1])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_g,rescale_a_g,[1.,1.],[1.,1.])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)\n",
    "        combined_v1 = combined_pred(pred_v1_test,pred_v1_test,rescale_a_g,rescale_a_g,[1.,0.1],[0.1,1.])\n",
    "        assert np.allclose(combined_v1,mean_v1_test)        \n",
    "        \n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a,rescale_a,[alpha_only_v2],[alpha_only_v2])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        \n",
    "        #ensure that combinations differ\n",
    "        assert np.allclose(combined_v1,combined_v2) is False\n",
    "        \n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_g,rescale_a_g,[alpha_nonlin_v2,gamma_nonlin_v2],[alpha_nonlin_v2,gamma_nonlin_v2])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_b_g,rescale_a_b_g,[alpha_v2,beta_v2,gamma_v2],[alpha_v2,beta_v2,gamma_v2])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        \n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a,rescale_a,[alpha_only_v2],[alpha_only_v2])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a,rescale_a,[alpha_only_v2],[1.])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a,rescale_a_b_g,[alpha_only_v2],[1.,1.,1.])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_b_g,rescale_a_b_g,[1.,1.,1.],[1.,1.,1.])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_b_g,rescale_a_b_g,[1.,0.1,1.],[0.1,1.,0.1])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_b_g,rescale_a_b_g,[1.,0.1,1.],[0.1,1.,0.1])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_g,rescale_a_g,[1.,1.],[1.,1.])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        combined_v2 = combined_pred(pred_v2_test,pred_v2_test,rescale_a_g,rescale_a_g,[1.,0.1],[0.1,1.])\n",
    "        assert np.allclose(combined_v2,mean_v2_test)\n",
    "        \n",
    "        combined_v1_v2 = combined_pred(pred_v1_test,pred_v2_test,rescale_a_g,rescale_a_g,[alpha_nonlin_v1,gamma_nonlin_v1],[alpha_nonlin_v2,gamma_nonlin_v2])\n",
    "        combined_v2_v1 = combined_pred(pred_v2_test,pred_v1_test,rescale_a_g,rescale_a_g,[alpha_nonlin_v2,gamma_nonlin_v2],[alpha_nonlin_v1,gamma_nonlin_v1])\n",
    "        #print(np.abs(combined_v1_v2-combined_v2_v1))\n",
    "        assert np.allclose(combined_v1_v2,combined_v2_v1)\n",
    "        \n",
    "        \n",
    "        combined_v1_v2 = combined_pred(pred_v1_test,pred_v2_test,rescale_a_b_g,rescale_a_g,[alpha_v1,beta_v1,gamma_v1],[alpha_nonlin_v2,gamma_nonlin_v2])\n",
    "        combined_v2_v1 = combined_pred(pred_v2_test,pred_v1_test,rescale_a_g,rescale_a_b_g,[alpha_nonlin_v2,gamma_nonlin_v2],[alpha_v1,beta_v1,gamma_v1])\n",
    "        #print(np.abs(combined_v1_v2-combined_v2_v1))\n",
    "        assert np.allclose(combined_v1_v2,combined_v2_v1)\n",
    "        \n",
    "    \n",
    "        if a_specie == 1:\n",
    "            pass\n",
    "            print(small_correction(alpha_only_v2,16))\n",
    "            print(RMSE_v2)\n",
    "            assert np.allclose(small_correction(alpha_only_v2,16),5.02753776,atol=1e-04)\n",
    "            assert(np.allclose(RMSE_v2,0.4777233772507114)) \n",
    "    \n",
    "    \n",
    "       \n",
    "#with open(\"rescaling_params_NN.json\",\"w\") as fg:\n",
    "#    json.dump(params_NN,fg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cff4286-96ec-4dc0-8bfc-f271e638f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.91948738])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_only_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb953b12-3d5e-46bb-84fb-0b2fd2db73f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (946170468.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_24624/946170468.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    species: 1, comb a : 0.00\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "species: 1, comb a : 0.00\n",
    "species: 1, comb a,g : 12.77\n",
    "species: 1, comb a,b,g : 12.82\n",
    "species: 1, comb a : 0.00\n",
    "species: 1, comb a,g : 0.00\n",
    "species: 1, comb a,b,g : 0.00\n",
    "Testing\n",
    "[5.02753776]\n",
    "0.4777233772507114\n",
    "species: 6, comb a : 0.00\n",
    "species: 6, comb a,g : 0.00\n",
    "species: 6, comb a,b,g : 0.00\n",
    "species: 6, comb a : 0.00\n",
    "species: 6, comb a,g : 0.00\n",
    "species: 6, comb a,b,g : 0.00\n",
    "Testing\n",
    "species: 7, comb a : 0.00\n",
    "species: 7, comb a,g : 2.21\n",
    "species: 7, comb a,b,g : 2.22\n",
    "species: 7, comb a : 16.80\n",
    "species: 7, comb a,g : 20.31\n",
    "species: 7, comb a,b,g : 21.79\n",
    "Testing\n",
    "species: 8, comb a : 5.66\n",
    "species: 8, comb a,g : 15.46\n",
    "species: 8, comb a,b,g : 15.48\n",
    "species: 8, comb a : 0.00\n",
    "species: 8, comb a,g : 0.00\n",
    "species: 8, comb a,b,g : 0.00"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92e6bac4-55d2-47d0-88d0-c3c2bb93f214",
   "metadata": {},
   "source": [
    "Tests:\n",
    "\n",
    "test (v1 + v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b741c14f-4606-431f-92a4-6ddbded690f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23410/3017664728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3420c12b-d55b-4559-a406-cd3ec215e4a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3245100638.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_22893/3245100638.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    torch LL: 13.299803823304574\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "torch LL: 13.299803823304574\n",
    "my LL: 13.299802780151367\n",
    "[5.40711451]\n",
    "1.2329739441615915 -1.216211102153372\n",
    "2.312352664107572 0.3817045349494603 -0.18021740322433935\n",
    "[5.02753773]\n",
    "torch LL: 10.855299993159452\n",
    "my LL: 10.85529899597168\n",
    "[4.41584696]\n",
    "4.339935318998906 -1.0345406553572736\n",
    "2.5363892609863417 3.1813801660338137 -0.034760850348700904\n",
    "[4.10332107]\n",
    "torch LL: 11.222066260903093\n",
    "my LL: 11.222066879272461\n",
    "[4.31009723]\n",
    "5.417401460339975 -0.5185490882038019\n",
    "3.1058851749568053 5.136410301275955 0.14370665262811044\n",
    "[4.00468639]\n",
    "torch LL: 10.173645105018178\n",
    "my LL: 10.17364501953125\n",
    "[3.91948771]\n",
    "7.1955332660982325 -0.8411707875486565\n",
    "1.8284555683297692 11.748788676836176 0.35652090500182354\n",
    "[3.64027005]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "307e7147-c88f-4acb-9534-af1cd445e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "b = np.array([1,2,3])\n",
    "print(*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d07ac-749f-4fec-b4c2-2671f22dd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch LL: 13.299803823304574\n",
    "my LL: 13.299802780151367\n",
    "[5.40711451]\n",
    "1.2329739441615915 -1.216211102153372\n",
    "2.312513144766872 0.38171130785928264 -0.18011772488824487\n",
    "[5.02753773]\n",
    "torch LL: 10.855299993159452\n",
    "my LL: 10.85529899597168\n",
    "[4.41584696]\n",
    "4.339935318998906 -1.0345406553572736\n",
    "4.339935505151607 1.2237235956918827e-05 -1.0345404704806083\n",
    "[4.10332107]\n",
    "torch LL: 11.222066260903093\n",
    "my LL: 11.222066879272461\n",
    "[4.31009723]\n",
    "5.417401460339975 -0.5185490882038019\n",
    "5.417401460339975 0.0 -0.5185490882038019\n",
    "[4.00468639]\n",
    "torch LL: 10.173645105018178\n",
    "my LL: 10.17364501953125\n",
    "[3.91948771]\n",
    "7.1955332660982325 -0.8411707875486565\n",
    "7.195551216400041 0.0 -0.8411736291447887\n",
    "[3.64027005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8de9cfd2-97b1-4a03-bfc8-59f96938f416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 4.303959087282078\n",
       " hess_inv: array([[235.31736518,   0.        , -37.02211963],\n",
       "       [  0.        ,   1.        ,   0.        ],\n",
       "       [-37.02211963,   0.        ,   6.61289986]])\n",
       "      jac: array([3.57627869e-07, 0.00000000e+00, 2.08616257e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 72\n",
       "      nit: 17\n",
       "     njev: 18\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 7.19555122,  0.        , -0.84117363])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(neglog_likelihood_a_b_c,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.,0.,0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e154567-d3de-4d4e-a482-359102d71bf5",
   "metadata": {},
   "source": [
    "## Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ccfe099b-f1b9-4179-9805-7bd2f16fd525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef neglog_likelihood_a(alpha,ystd,ymeans,ytrue,nll=neglog_likelihood):\\n    ystd = alpha * ystd \\n    return nll(ystd,ymeans,ytrue)\\n\\ndef neglog_likelihood_a_g(x,ystd,ymeans,ytrue,nll=neglog_likelihood):\\n    alpha = x[0]\\n    gamma = x[1]\\n    ystd = np.sqrt(alpha**2 * ystd**(gamma+2))\\n    return nll(ystd,ymeans,ytrue)    \\n\\ndef neglog_likelihood_a_b_g(x,ystd,ymeans,ytrue,nll=neglog_likelihood):\\n    alpha = x[0]\\n    beta = x[1]\\n    gamma = x[2]\\n    ystd = np.sqrt(alpha**2 * ystd**(gamma+2) + beta**2)\\n    return nll(ystd,ymeans,ytrue)\\n    \\n\\nalpha_only = minimize(neglog_likelihood_a,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.]))[\"x\"]\\nalpha_nonlin, gamma_nonlin = minimize(neglog_likelihood_a_g,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.,0.]))[\"x\"]\\nalpha, beta, gamma = minimize(neglog_likelihood_a_b_g,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.,0.,0.]))[\"x\"]\\n\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    def neglog_likelihood_a(alpha,ystd,ymeans,ytrue,nll=neglog_likelihood):\n",
    "        ystd = alpha * ystd \n",
    "        return nll(ystd,ymeans,ytrue)\n",
    "\n",
    "    def neglog_likelihood_a_g(x,ystd,ymeans,ytrue,nll=neglog_likelihood):\n",
    "        alpha = x[0]\n",
    "        gamma = x[1]\n",
    "        ystd = np.sqrt(alpha**2 * ystd**(gamma+2))\n",
    "        return nll(ystd,ymeans,ytrue)    \n",
    "    \n",
    "    def neglog_likelihood_a_b_g(x,ystd,ymeans,ytrue,nll=neglog_likelihood):\n",
    "        alpha = x[0]\n",
    "        beta = x[1]\n",
    "        gamma = x[2]\n",
    "        ystd = np.sqrt(alpha**2 * ystd**(gamma+2) + beta**2)\n",
    "        return nll(ystd,ymeans,ytrue)\n",
    "        \n",
    "\n",
    "    alpha_only = minimize(neglog_likelihood_a,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.]))[\"x\"]\n",
    "    alpha_nonlin, gamma_nonlin = minimize(neglog_likelihood_a_g,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.,0.]))[\"x\"]\n",
    "    alpha, beta, gamma = minimize(neglog_likelihood_a_b_g,args=(ystd_data_v2,ymeans_data_v2,ytrue_data_v2),x0=np.array([1.,0.,0.]))[\"x\"]\n",
    "    \n",
    "    \"\"\"\n",
    "        #print(\"torch LL: {}\".format(neglog_likelihood(ystd_data_v2,ymeans_data_v2,ytrue_data_v2)))\n",
    "    #print(\"my LL: {}\".format(neglog_likelihood_torch(ystd_data_v2,ymeans_data_v2,ytrue_data_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1f0e-1d28-4db8-8608-642efd2c056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    example:\n",
    "    torch LL: 0.6961718892174772\n",
    "    my LL: 0.6961718892174772\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
